
@article{andersonValuedrivenAttentionalCapture2011,
  title = {Value-Driven Attentional Capture},
  author = {Anderson, B.A. and Laurent, P.A. and Yantis, S},
  year = {2011},
  month = jun,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {108},
  number = {25},
  pages = {10367--10371},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1104047108},
  abstract = {Attention selects which aspects of sensory input are brought to awareness. To promote survival and well-being, attention prioritizes stimuli both voluntarily, according to context-specific goals (e.g., searching for car keys), and involuntarily, through attentional capture driven by physical salience (e.g., looking toward a sudden noise). Valuable stimuli strongly modulate voluntary attention allocation, but there is little evidence that high-value but contextually irrelevant stimuli capture attention as a consequence of reward learning. Here we show that visual search for a salient target is slowed by the presence of an inconspicuous, task-irrelevant item that was previously associated with monetary reward during a brief training session. Thus, arbitrary and otherwise neutral stimuli imbued with value via associative learning capture attention powerfully and persistently during extinction, independently of goals and salience. Vulnerability to such value-driven attentional capture covaries across individuals with working memory capacity and trait impulsivity. This unique form of attentional capture may provide a useful model for investigating failures of cognitive control in clinical syndromes in which value assigned to stimuli conflicts with behavioral goals (e.g., addiction, obesity).},
  chapter = {Biological Sciences},
  langid = {english},
  pmid = {21646524},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/6ZKL2SBL/Anderson et al. - 2011 - Value-driven attentional capture.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/V7DI46UB/10367.html}
}

@article{awhTopdownBottomupAttentional2012,
  title = {Top-down versus Bottom-up Attentional Control: A Failed Theoretical Dichotomy},
  shorttitle = {Top-down versus Bottom-up Attentional Control},
  author = {Awh, Edward and Belopolsky, Artem V. and Theeuwes, Jan},
  year = {2012},
  month = aug,
  journal = {Trends in Cognitive Sciences},
  volume = {16},
  number = {8},
  pages = {437--443},
  issn = {1879-307X},
  doi = {10.1016/j.tics.2012.06.010},
  abstract = {Prominent models of attentional control assert a dichotomy between top-down and bottom-up control, with the former determined by current selection goals and the latter determined by physical salience. This theoretical dichotomy, however, fails to explain a growing number of cases in which neither current goals nor physical salience can account for strong selection biases. For example, equally salient stimuli associated with reward can capture attention, even when this contradicts current selection goals. Thus, although 'top-down' sources of bias are sometimes defined as those that are not due to physical salience, this conception conflates distinct--and sometimes contradictory--sources of selection bias. We describe an alternative framework, in which past selection history is integrated with current goals and physical salience to shape an integrated priority map.},
  langid = {english},
  pmcid = {PMC3426354},
  pmid = {22795563},
  keywords = {Attention,Discrimination; Psychological,Humans,Pattern Recognition; Visual,Photic Stimulation,Psychological Theory},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/7IEIT8CU/Awh et al. - 2012 - Top-down versus bottom-up attentional control a f.pdf}
}

@article{bachmanPhysicalSalienceValueDriven2020,
  title = {Physical {{Salience}} and {{Value-Driven Salience Operate}} through {{Different Neural Mechanisms}} to {{Enhance Attentional Selection}}},
  author = {Bachman, Matthew D. and Wang, Lingling and Gamble, Marissa L. and Woldorff, Marty G.},
  year = {2020},
  month = jul,
  journal = {Journal of Neuroscience},
  volume = {40},
  number = {28},
  pages = {5455--5464},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1198-19.2020},
  abstract = {Previous studies have indicated that both increased physical salience and increased reward-value salience of a target improve behavioral measures of attentional selection. It is unclear, however, whether these two forms of salience interact with attentional networks through similar or different neural mechanisms, and what such differences might be. We examined this question by separately manipulating both the value-driven and physical salience of targets in a visual search task while recording response times (RTs) and event-related potentials, focusing on the attentional-orienting-sensitive N2pc event-related potential component. Human participants of both sexes searched arrays for targets of either a high-physical-salience color or one of two low-physical-salience colors across three experimental phases. The first phase (``baseline'') offered no rewards. RT and N2pc latencies were shorter for high-physical-salience targets, indicating faster attentional orienting. In the second phase (``equal-reward''), a low monetary reward was given for fast correct responses for all target types. This reward context improved overall performance, similarly shortening RTs and enhancing N2pc amplitudes for all target types, but with no change in N2pc latencies. In the third phase (``selective-reward''), the reward rate was made selectively higher for one of the two low-physical-salience colors, resulting in their RTs becoming as fast as the high-physical-salience targets. Despite the equally fast RTs, the N2pc's for these low-physical-salience, high-value targets remained later than for high-physical-salience targets, instead eliciting significantly larger N2pc's. These results suggest that enhanced physical salience leads to faster attentional orienting, but value-driven salience to stronger attentional orienting, underscoring the utilization of different underlying mechanisms. SIGNIFICANCE STATEMENT Associating relevant target stimuli with reward value can enhance their salience, facilitating their attentional selection. This value-driven salience improves behavioral performance, similar to the effects of physical salience. Recent theories, however, suggest that these forms of salience are intrinsically different, although the neural mechanisms underlying any such differences remain unclear. This study addressed this issue by manipulating the physical and value-related salience of targets in a visual search task, comparing their effects on several attention-sensitive neural-activity measures. Our findings show that, whereas physical salience accelerates the speed of attentional selection, value-driven salience selectively enhances its strength. These findings shed new insights into the theoretical and neural underpinnings of value-driven salience and its effects on attention and behavior.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2020 the authors},
  langid = {english},
  pmid = {32471878},
  keywords = {attention,attentional capture,EEG,N2pc,reward,value},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/S6ETP9YB/Bachman et al. - 2020 - Physical Salience and Value-Driven Salience Operat.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/Z95LG6SR/5455.html}
}

@article{barrRandomEffectsStructure2013,
  title = {Random Effects Structure for Confirmatory Hypothesis Testing: {{Keep}} It Maximal},
  shorttitle = {Random Effects Structure for Confirmatory Hypothesis Testing},
  author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
  year = {2013},
  month = apr,
  journal = {Journal of Memory and Language},
  volume = {68},
  number = {3},
  pages = {255--278},
  issn = {0749-596X},
  doi = {10.1016/j.jml.2012.11.001},
  abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the `gold standard' for confirmatory hypothesis testing in psycholinguistics and beyond.},
  langid = {english},
  keywords = {Generalization,Linear mixed-effects models,Monte Carlo simulation,Statistics},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/DFMN2XF6/Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/7JRBYVVU/S0749596X12001180.html}
}

@article{beyelerNeuralCorrelatesSparse2019,
  title = {Neural Correlates of Sparse Coding and Dimensionality Reduction},
  author = {Beyeler, M and Rounds, E.L. and Carlson, K.D. and Dutt, N and Krichmar, J.L.},
  year = {2019},
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {15},
  number = {6},
  pages = {e1006908},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1006908},
  abstract = {Supported by recent computational studies, there is increasing evidence that a wide range of neuronal responses can be understood as an emergent property of nonnegative sparse coding (NSC), an efficient population coding scheme based on dimensionality reduction and sparsity constraints. We review evidence that NSC might be employed by sensory areas to efficiently encode external stimulus spaces, by some associative areas to conjunctively represent multiple behaviorally relevant variables, and possibly by the basal ganglia to coordinate movement. In addition, NSC might provide a useful theoretical framework under which to understand the often complex and nonintuitive response properties of neurons in other brain areas. Although NSC might not apply to all brain areas (for example, motor or executive function areas) the success of NSC-based models, especially in sensory areas, warrants further investigation for neural correlates in other regions.},
  langid = {english},
  keywords = {Basal ganglia,Behavior,Coding mechanisms,Face,Neurons,Sensory perception,Vision,Visual cortex},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/Q6C3P2DR/Beyeler et al. - 2019 - Neural correlates of sparse coding and dimensional.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/QHHAMZGJ/article.html}
}

@article{blancaEffectVarianceRatio2018,
  title = {Effect of Variance Ratio on {{ANOVA}} Robustness: {{Might}} 1.5 Be the Limit?},
  shorttitle = {Effect of Variance Ratio on {{ANOVA}} Robustness},
  author = {Blanca, M.J. and Alarc{\'o}n, R. and Arnau, J and Bono, R and Bendayan, R},
  year = {2018},
  month = jun,
  journal = {Behavior Research Methods},
  volume = {50},
  number = {3},
  pages = {937--962},
  issn = {1554-3528},
  doi = {10.3758/s13428-017-0918-2},
  abstract = {Inconsistencies in the research findings on F-test robustness to variance heterogeneity could be related to the lack of a standard criterion to assess robustness or to the different measures used to quantify heterogeneity. In the present paper we use Monte Carlo simulation to systematically examine the Type I error rate of F-test under heterogeneity. One-way, balanced, and unbalanced designs with monotonic patterns of variance were considered. Variance ratio (VR) was used as a measure of heterogeneity (1.5, 1.6, 1.7, 1.8, 2, 3, 5, and 9), the coefficient of sample size variation as a measure of inequality between group sizes (0.16, 0.33, and 0.50), and the correlation between variance and group size as an indicator of the pairing between them (1, .50, 0, -.50, and -1). Overall, the results suggest that in terms of Type I error a VR above 1.5 may be established as a rule of thumb for considering a potential threat to F-test robustness under heterogeneity with unequal sample sizes.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/N55CKNJF/Blanca et al. - 2018 - Effect of variance ratio on ANOVA robustness Migh.pdf}
}

@article{boormanCounterfactualChoiceLearning2011a,
  title = {Counterfactual {{Choice}} and {{Learning}} in a {{Neural Network Centered}} on {{Human Lateral Frontopolar Cortex}}},
  author = {Boorman, E.D. and Behrens, T.E. and Rushworth, M.F.},
  year = {2011},
  month = jun,
  journal = {PLOS Biology},
  volume = {9},
  number = {6},
  pages = {e1001093},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.1001093},
  abstract = {Decision making and learning in a real-world context require organisms to track not only the choices they make and the outcomes that follow but also other untaken, or counterfactual, choices and their outcomes. Although the neural system responsible for tracking the value of choices actually taken is increasingly well understood, whether a neural system tracks counterfactual information is currently unclear. Using a three-alternative decision-making task, a Bayesian reinforcement-learning algorithm, and fMRI, we investigated the coding of counterfactual choices and prediction errors in the human brain. Rather than representing evidence favoring multiple counterfactual choices, lateral frontal polar cortex (lFPC), dorsomedial frontal cortex (DMFC), and posteromedial cortex (PMC) encode the reward-based evidence favoring the best counterfactual option at future decisions. In addition to encoding counterfactual reward expectations, the network carries a signal for learning about counterfactual options when feedback is available\textemdash a counterfactual prediction error. Unlike other brain regions that have been associated with the processing of counterfactual outcomes, counterfactual prediction errors within the identified network cannot be related to regret theory. Furthermore, individual variation in counterfactual choice-related activity and prediction error-related activity, respectively, predicts variation in the propensity to switch to profitable choices in the future and the ability to learn from hypothetical feedback. Taken together, these data provide both neural and behavioral evidence to support the existence of a previously unidentified neural system responsible for tracking both counterfactual choice options and their outcomes.},
  langid = {english},
  keywords = {Behavior,Coding mechanisms,Decision making,Functional magnetic resonance imaging,Human learning,Learning,Monkeys,Phase determination},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/M4DQB4LS/Boorman et al. - 2011 - Counterfactual Choice and Learning in a Neural Net.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/CRYKJSVE/article.html}
}

@article{botvinickComputationalNeuralBasis2014,
  title = {The {{Computational}} and {{Neural Basis}} of {{Cognitive Control}}: {{Charted Territory}} and {{New Frontiers}}},
  shorttitle = {The {{Computational}} and {{Neural Basis}} of {{Cognitive Control}}},
  author = {Botvinick, Matthew M. and Cohen, Jonathan D.},
  year = {2014},
  journal = {Cognitive Science},
  volume = {38},
  number = {6},
  pages = {1249--1285},
  issn = {1551-6709},
  doi = {10.1111/cogs.12126},
  abstract = {Cognitive control has long been one of the most active areas of computational modeling work in cognitive science. The focus on computational models as a medium for specifying and developing theory predates the PDP books, and cognitive control was not one of the areas on which they focused. However, the framework they provided has injected work on cognitive control with new energy and new ideas. On the occasion of the books' anniversary, we review computational modeling in the study of cognitive control, with a focus on the influence that the PDP approach has brought to bear in this area. Rather than providing a comprehensive review, we offer a framework for thinking about past and future modeling efforts in this domain. We define control in terms of the optimal parameterization of task processing. From this vantage point, the development of control systems in the brain can be seen as responding to the structure of naturalistic tasks, through the filter of the brain systems with which control directly interfaces. This perspective lays open a set of fascinating but difficult research questions, which together define an important frontier for future computational research.},
  copyright = {Copyright \textcopyright{} 2014 Cognitive Science Society, Inc.},
  langid = {english},
  keywords = {Cognitive control,Computational modeling},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12126},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/BUWJW4AY/Botvinick and Cohen - 2014 - The Computational and Neural Basis of Cognitive Co.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/KHSDMBT4/cogs.html}
}

@article{brainardPsychophysicsToolbox1997,
  ids = {brainardPsychophysicsToolbox1997a},
  title = {The {{Psychophysics Toolbox}}},
  author = {Brainard, D. H.},
  year = {1997},
  journal = {Spatial Vision},
  volume = {10},
  number = {4},
  pages = {433--436},
  publisher = {{Brill}},
  issn = {0169-1015},
  abstract = {The Psychophysics Toolbox is a software package that supports visual psychophysics. Its routines provide an interface between a high-level interpreted language (MATLAB on the Macintosh) and the video display hardware. A set of example programs is included with the Toolbox distribution.},
  chapter = {Spatial Vision},
  langid = {english},
  pmid = {9176952},
  keywords = {Computer Terminals,Data Display,Humans,Microcomputers,Psychophysics,Research,Software,User-Computer Interface},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/N4GQCAU7/Brainard - 1997 - The Psychophysics Toolbox.pdf}
}

@book{bruyaEffortlessAttentionNew2010,
  title = {Effortless {{Attention}}: {{A New Perspective}} in the {{Cognitive Science}} of {{Attention}} and {{Action}}},
  shorttitle = {Effortless {{Attention}}},
  author = {Bruya, Brian and Lewthwaite, Rebecca and Ackerman, Joshua M. and Austin, James H. and Bargh, John A. and Baumeister, Roy F. and Beilock, Sian L. and Botvinick, Matthew M. and Csikszentmihalyi, Mihaly and DeCaro, Marci S.},
  year = {2010},
  publisher = {{MIT Press}},
  address = {{Cambridge, UNITED STATES}},
  abstract = {The phenomena of effortless attention and action and the challenges they pose to current cognitive models of attention and action. This is the first book to explore the cognitive science of effortless attention and action. Attention and action are generally understood to require effort, and the expectation is that under normal circumstances effort increases to meet rising demand. Sometimes, however, attention and action seem to flow effortlessly despite high demand. Effortless attention and action have been documented across a range of normal activities--ranging from rock climbing to chess playing--and yet fundamental questions about the cognitive science of effortlessness have gone largely unasked. This book draws from the disciplines of cognitive psychology, neurophysiology, behavioral psychology, genetics, philosophy, and cross-cultural studies. Starting from the premise that the phenomena of effortless attention and action provide an opportunity to test current models of attention and action, leading researchers from around the world examine topics including effort as a cognitive resource, the role of effort in decision-making, the neurophysiology of effortless attention and action, the role of automaticity in effortless action, expert performance in effortless action, and the neurophysiology and benefits of attentional training. Contributors Joshua M. Ackerman, James H. Austin, John A. Bargh Roy F. Baumeister, Sian L. Beilock, Chris Blais, Matthew M. Botvinick, Brian Bruya, Mihaly Csikszentmihalyi, Marci S. DeCaro, Arne Dietrich, Yuri Dormashev, L\'aszl\'o Harmat, Bernhard Hommel, Rebecca Lewthwaite, \"Orjan de Manzano, Joseph T. McGuire, Brian P. Meier, Arlen C. Moller, Jeanne Nakamura, Michael I. Posner, Mary K. Rothbart, M.R. Rueda, Brandon J. Schmeichel, Edward Slingerland, Oliver Stoll, Yiyuan Tang, T\"ores Theorell, Fredrik Ull\'en, Gabriele Wulf},
  isbn = {978-0-262-26943-8},
  keywords = {Attention.,Cognitive neuroscience.}
}

@article{brydevallNeuralEncodingInformation2018,
  title = {The Neural Encoding of Information Prediction Errors during Non-Instrumental Information Seeking},
  author = {Brydevall, M. and Bennett, D. and Murawski, C. and Bode, S.},
  year = {2018},
  month = apr,
  journal = {Scientific Reports},
  volume = {8},
  number = {1},
  pages = {6134},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-018-24566-x},
  abstract = {In a dynamic world, accurate beliefs about the environment are vital for survival, and individuals should therefore regularly seek out new information with which to update their beliefs. This aspect of behaviour is not well captured by standard theories of decision making, and the neural mechanisms of information seeking remain unclear. One recent theory posits that valuation of information results from representation of informative stimuli within canonical neural reward-processing circuits, even if that information lacks instrumental use. We investigated this question by recording EEG from twenty-three human participants performing a non-instrumental information-seeking task. In this task, participants could pay a monetary cost to receive advance information about the likelihood of receiving reward in a lottery at the end of each trial. Behavioural results showed that participants were willing to incur considerable monetary costs to acquire early but non-instrumental information. Analysis of the event-related potential elicited by informative cues revealed that the feedback-related negativity independently encoded both an information prediction error and a reward prediction error. These findings are consistent with the hypothesis that information seeking results from processing of information within neural reward circuits, and suggests that information may represent a distinct dimension of valuation in decision making under uncertainty.},
  copyright = {2018 The Author(s)},
  langid = {english},
  keywords = {Decision,Human behaviour},
  annotation = {Bandiera\_abtest: a Cc\_license\_type: cc\_by Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Decision;Human behaviour Subject\_term\_id: decision;human-behaviour},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/N9P7FCNT/Brydevall et al. - 2018 - The neural encoding of information prediction erro.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/CQK5QZDQ/s41598-018-24566-x.html}
}

@article{burgLearningDivisiveNormalization2021a,
  title = {Learning Divisive Normalization in Primary Visual Cortex},
  author = {Burg, Max F. and Cadena, Santiago A. and Denfield, George H. and Walker, Edgar Y. and Tolias, Andreas S. and Bethge, Matthias and Ecker, Alexander S.},
  year = {2021},
  month = jun,
  journal = {PLOS Computational Biology},
  volume = {17},
  number = {6},
  pages = {e1009028},
  publisher = {{Public Library of Science}},
  issn = {1553-7358},
  doi = {10.1371/journal.pcbi.1009028},
  abstract = {Divisive normalization (DN) is a prominent computational building block in the brain that has been proposed as a canonical cortical operation. Numerous experimental studies have verified its importance for capturing nonlinear neural response properties to simple, artificial stimuli, and computational studies suggest that DN is also an important component for processing natural stimuli. However, we lack quantitative models of DN that are directly informed by measurements of spiking responses in the brain and applicable to arbitrary stimuli. Here, we propose a DN model that is applicable to arbitrary input images. We test its ability to predict how neurons in macaque primary visual cortex (V1) respond to natural images, with a focus on nonlinear response properties within the classical receptive field. Our model consists of one layer of subunits followed by learned orientation-specific DN. It outperforms linear-nonlinear and wavelet-based feature representations and makes a significant step towards the performance of state-of-the-art convolutional neural network (CNN) models. Unlike deep CNNs, our compact DN model offers a direct interpretation of the nature of normalization. By inspecting the learned normalization pool of our model, we gained insights into a long-standing question about the tuning properties of DN that update the current textbook description: we found that within the receptive field oriented features were normalized preferentially by features with similar orientation rather than non-specifically as currently assumed.},
  langid = {english},
  keywords = {Convolution,Forecasting,Monkeys,Neural networks,Neuronal tuning,Neurons,Vision,Visual cortex},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/8WTFL26Y/Burg et al. - 2021 - Learning divisive normalization in primary visual .pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/Y6WDZM6E/article.html}
}

@article{buschmanBehaviorNeuralDynamics2015,
  title = {From Behavior to Neural Dynamics: {{An}} Integrated Theory of Attention},
  shorttitle = {From Behavior to Neural Dynamics},
  author = {Buschman, T.J. and Kastner, S.},
  year = {2015},
  month = oct,
  journal = {Neuron},
  volume = {88},
  number = {1},
  pages = {127--144},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2015.09.017},
  abstract = {The brain has a limited capacity and therefore needs mechanisms to selectively enhance the information most relevant to one's current behavior. We refer to these mechanisms as `attention'. Attention acts by increasing the strength of selected neural representations and preferentially routing them through the brain's large-scale network. This is a critical component of cognition and therefore has been a central topic in cognitive neuroscience. Here we review a diverse literature that has studied attention at the level of behavior, networks, circuits and neurons. We then integrate these disparate results into a unified theory of attention.},
  pmcid = {PMC4604109},
  pmid = {26447577},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/FGPUAXST/Buschman and Kastner - 2015 - From behavior to neural dynamics An integrated th.pdf}
}

@article{carrascoVisualAttention252011a,
  title = {Visual Attention: {{The}} Past 25 Years},
  shorttitle = {Visual Attention},
  author = {Carrasco, M.},
  year = {2011},
  month = jul,
  journal = {Vision Research},
  series = {Vision {{Research}} 50th {{Anniversary Issue}}: {{Part}} 2},
  volume = {51},
  number = {13},
  pages = {1484--1525},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2011.04.012},
  abstract = {This review focuses on covert attention and how it alters early vision. I explain why attention is considered a selective process, the constructs of covert attention, spatial endogenous and exogenous attention, and feature-based attention. I explain how in the last 25years research on attention has characterized the effects of covert attention on spatial filters and how attention influences the selection of stimuli of interest. This review includes the effects of spatial attention on discriminability and appearance in tasks mediated by contrast sensitivity and spatial resolution; the effects of feature-based attention on basic visual processes, and a comparison of the effects of spatial and feature-based attention. The emphasis of this review is on psychophysical studies, but relevant electrophysiological and neuroimaging studies and models regarding how and where neuronal responses are modulated are also discussed.},
  langid = {english},
  keywords = {Appearance,Attention models,Contrast sensitivity,Covert attention,Endogenous attention,Exogenous attention,Feature-based attention,Neurophysiology of attention,Performance,Psychophysics,Spatial attention,Spatial resolution,Sustained attention,Transient attention},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/JZNJJQ83/Carrasco - 2011 - Visual attention The past 25 years.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/LJ5BEU9C/S0042698911001544.html}
}

@article{chelazziAlteringSpatialPriority2014,
  title = {Altering {{Spatial Priority Maps}} via {{Reward-Based Learning}}},
  author = {Chelazzi, L and E{\v s}to{\v c}inov{\'a}, J. and Calletti, R. and Gerfo, E.L. and Sani, I. and Libera, C.D. and Santandrea, E.},
  year = {2014},
  month = jun,
  journal = {Journal of Neuroscience},
  volume = {34},
  number = {25},
  pages = {8594--8604},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.0277-14.2014},
  abstract = {Spatial priority maps are real-time representations of the behavioral salience of locations in the visual field, resulting from the combined influence of stimulus driven activity and top-down signals related to the current goals of the individual. They arbitrate which of a number of (potential) targets in the visual scene will win the competition for attentional resources. As a result, deployment of visual attention to a specific spatial location is determined by the current peak of activation (corresponding to the highest behavioral salience) across the map. Here we report a behavioral study performed on healthy human volunteers, where we demonstrate that spatial priority maps can be shaped via reward-based learning, reflecting long-lasting alterations (biases) in the behavioral salience of specific spatial locations. These biases exert an especially strong influence on performance under conditions where multiple potential targets compete for selection, conferring competitive advantage to targets presented in spatial locations associated with greater reward during learning relative to targets presented in locations associated with lesser reward. Such acquired biases of spatial attention are persistent, are nonstrategic in nature, and generalize across stimuli and task contexts. These results suggest that reward-based attentional learning can induce plastic changes in spatial priority maps, endowing these representations with the ``intelligent'' capacity to learn from experience.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2014 the authors 0270-6474/14/348594-11\$15.00/0},
  langid = {english},
  pmid = {24948813},
  keywords = {cross-target competition,reward-based learning,spatial attention,spatial priority maps},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/JAMJS8EY/Chelazzi et al. - 2014 - Altering Spatial Priority Maps via Reward-Based Le.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/NN3CCRGH/8594.html}
}

@article{chelazziRewardsTeachVisual2013a,
  title = {Rewards Teach Visual Selective Attention},
  author = {Chelazzi, L. and Perlato, A. and Santandrea, E. and Della Libera, C.},
  year = {2013},
  month = jun,
  journal = {Vision Research},
  series = {Visual {{Attention}} 2013 {{Volume II}}},
  volume = {85},
  pages = {58--72},
  issn = {0042-6989},
  doi = {10.1016/j.visres.2012.12.005},
  abstract = {Visual selective attention is the brain function that modulates ongoing processing of retinal input in order for selected representations to gain privileged access to perceptual awareness and guide behavior. Enhanced analysis of currently relevant or otherwise salient information is often accompanied by suppressed processing of the less relevant or salient input. Recent findings indicate that rewards exert a powerful influence on the deployment of visual selective attention. Such influence takes different forms depending on the specific protocol adopted in the given study. In some cases, the prospect of earning a larger reward in relation to a specific stimulus or location biases attention accordingly in order to maximize overall gain. This is mediated by an effect of reward acting as a type of incentive motivation for the strategic control of attention. In contrast, reward delivery can directly alter the processing of specific stimuli by increasing their attentional priority, and this can be measured even when rewards are no longer involved, reflecting a form of reward-mediated attentional learning. As a further development, recent work demonstrates that rewards can affect attentional learning in dissociable ways depending on whether rewards are perceived as feedback on performance or instead are registered as random-like events occurring during task performance. Specifically, it appears that visual selective attention is shaped by two distinct reward-related learning mechanisms: one requiring active monitoring of performance and outcome, and a second one detecting the sheer association between objects in the environment (whether attended or ignored) and the more-or-less rewarding events that accompany them. Overall this emerging literature demonstrates unequivocally that rewards ``teach'' visual selective attention so that processing resources will be allocated to objects, features and locations which are likely to optimize the organism's interaction with the surrounding environment and maximize positive outcome.},
  langid = {english},
  keywords = {Attentional learning,Motivation,Reward,Visual processing,Visual selective attention}
}

@article{chenCounterfactualCriticMultiAgent2019,
  title = {Counterfactual {{Critic Multi-Agent Training}} for {{Scene Graph Generation}}},
  author = {Chen, Long and Zhang, Hanwang and Xiao, Jun and He, Xiangnan and Pu, Shiliang and Chang, Shih-Fu},
  year = {2019},
  month = aug,
  journal = {arXiv:1812.02347 [cs]},
  eprint = {1812.02347},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Scene graphs -- objects as nodes and visual relationships as edges -- describe the whereabouts and interactions of the things and stuff in an image for comprehensive scene understanding. To generate coherent scene graphs, almost all existing methods exploit the fruitful visual context by modeling message passing among objects, fitting the dynamic nature of reasoning with visual context, eg, "person" on "bike" can help to determine the relationship "ride", which in turn contributes to the category confidence of the two objects. However, we argue that the scene dynamics is not properly learned by using the prevailing cross-entropy based supervised learning paradigm, which is not sensitive to graph inconsistency: errors at the hub or non-hub nodes are unfortunately penalized equally. To this end, we propose a Counterfactual critic Multi-Agent Training (CMAT) approach to resolve the mismatch. CMAT is a multi-agent policy gradient method that frames objects as cooperative agents, and then directly maximizes a graph-level metric as the reward. In particular, to assign the reward properly to each agent, CMAT uses a counterfactual baseline that disentangles the agent-specific reward by fixing the dynamics of other agents. Extensive validations on the challenging Visual Genome benchmark show that CMAT achieves a state-of-the-art by significant performance gains under various settings and metrics.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/RXY8736U/Chen et al. - 2019 - Counterfactual Critic Multi-Agent Training for Sce.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/35MX9C9N/1812.html}
}

@article{chicaSpatialOrientingParadigm2014a,
  title = {The {{Spatial Orienting}} Paradigm: {{How}} to Design and Interpret Spatial Attention Experiments},
  shorttitle = {The {{Spatial Orienting}} Paradigm},
  author = {Chica, A{$>$}B. and {Mart{\'i}n-Ar{\'e}valo}, E. and Botta, F. and Lupi{\'a}{\~n}ez, J.},
  year = {2014},
  month = mar,
  journal = {Neuroscience \& Biobehavioral Reviews},
  volume = {40},
  pages = {35--51},
  issn = {0149-7634},
  doi = {10.1016/j.neubiorev.2014.01.002},
  abstract = {This paper is conceived as a guide that will describe the very well known Spatial Orienting paradigm, used to explore attentional processes in healthy individuals as well as in people suffering from psychiatric disorders and brain-damaged patients. The paradigm was developed in the late 1970s, and since then, it has been used in thousands of attentional studies. In this review, we attempt to describe, the paradigm for the na\"if reader, and explain in detail when is it used, which variables are usually manipulated, how to interpret its results, and how can it be adapted to different populations and methodologies. The main goal of this review is to provide a practical guide to researchers who have never used the paradigm that will help them design their experiments, as a function of their theoretical and experimental needs. We also focus on how to adapt the paradigm to different technologies (such as event-related potentials, functional resonance imaging, or transcranial magnetic stimulation), and to different populations by presenting an example of its use in brain-damaged patients.},
  langid = {english},
  keywords = {Attention,Facilitation,Inhibition of Return,Spatial orienting,Validity},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/IYAJ76PZ/S0149763414000050.html}
}

@article{desimoneNeuralMechanismsSelective1995a,
  title = {Neural {{Mechanisms}} of {{Selective Visual Attention}}},
  author = {Desimone, R. and Duncan, J.},
  year = {1995},
  journal = {Annual Review of Neuroscience},
  volume = {18},
  number = {1},
  pages = {193--222},
  doi = {10.1146/annurev.ne.18.030195.001205},
  pmid = {7605061},
  keywords = {cortex,neglect,primates,vision,visual search},
  annotation = {\_eprint: https://doi.org/10.1146/annurev.ne.18.030195.001205},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/V29T2P5R/Desimone and Duncan - 1995 - Neural Mechanisms of Selective Visual Attention.pdf}
}

@article{dolanGoalsHabitsBrain2013,
  title = {Goals and {{Habits}} in the {{Brain}}},
  author = {Dolan, R.J. and Dayan, P.},
  year = {2013},
  month = oct,
  journal = {Neuron},
  volume = {80},
  number = {2},
  pages = {312--325},
  issn = {0896-6273},
  doi = {10.1016/j.neuron.2013.09.007},
  abstract = {An enduring and richly elaborated dichotomy in cognitive neuroscience is that of reflective versus reflexive decision making and choice. Other literatures refer to the two ends of what is likely to be a spectrum with terms such as goal-directed versus habitual, model-based versus model-free or prospective versus retrospective. One of the most rigorous traditions of experimental work in the field started with studies in rodents and graduated via human versions and enrichments of those experiments to a current state in which new paradigms are probing and challenging the very heart of the distinction. We review four generations of work in this tradition and provide pointers to the forefront of the field's fifth generation.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/GDCHUHEK/Dolan and Dayan - 2013 - Goals and Habits in the Brain.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/8K2P6SQ4/S0896627313008052.html}
}

@article{dunn+WellSeparatedClustersOptimal1974,
  title = {Well-{{Separated Clusters}} and {{Optimal Fuzzy Partitions}}},
  author = {Dunn{\textdagger}, J. C.},
  year = {1974},
  month = jan,
  journal = {Journal of Cybernetics},
  volume = {4},
  number = {1},
  pages = {95--104},
  publisher = {{Taylor \& Francis}},
  issn = {0022-0280},
  doi = {10.1080/01969727408546059},
  abstract = {Two separation indices are considered for partitions P = X1, \ldots, Xk of a finite data set X in a general inner product space. Both indices increase as the pairwise distances between the subsets Xi become large compared to the diameters of Xi Maximally separated partitions p' are defined and it is shown that as the indices of p' increase without bound, the characteristic functions of Xi' in P' are approximated more and more closely by the membership functions in fuzzy partitions which minimize certain fuzzy extensions of the k-means squared error criterion function.},
  annotation = {\_eprint: https://doi.org/10.1080/01969727408546059},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/9UUI62YV/Dunnâ€  - 1974 - Well-Separated Clusters and Optimal Fuzzy Partitio.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/3PYGDCIH/01969727408546059.html}
}

@article{embreyYouWantKnow,
  title = {Do You Want to Know a Secret? {{The}} Role of Valence and Delay in Early Information Preference},
  author = {Embrey, Jake R and Navarro, Danielle},
  pages = {7},
  abstract = {People tend to place value on information even when it does not affect the outcome of a decision. Two competing accounts offer explanations for such non-instrumental information seeking. One account foregrounds the role of anticipation and the other focusses on uncertainty aversion. Both accounts make similar predictions for short cueoutcome delays and when outcomes are positively valenced, but they differ in their explanation of information preference at long delays with negative outcomes. We present a series of experiments involving both primary and secondary reinforcers that pit these accounts against each other. The results indicate a consistent preference for non-instrumental information even at long cue-outcome delays and no evidence for information avoidance with negative outcomes. This pattern appears to provide more support for the uncertainty-aversion account than one based on anticipation.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/UL3YEA7Y/Embrey and Navarro - Do you want to know a secret The role of valence .pdf}
}

@article{failingSelectionHistoryHow2018,
  title = {Selection History: {{How}} Reward Modulates Selectivity of Visual Attention},
  shorttitle = {Selection History},
  author = {Failing, M. and Theeuwes, J.},
  year = {2018},
  month = apr,
  journal = {Psychonomic Bulletin \& Review},
  volume = {25},
  number = {2},
  pages = {514--538},
  issn = {1531-5320},
  doi = {10.3758/s13423-017-1380-y},
  abstract = {Visual attention enables us to selectively prioritize or suppress information in the environment. Prominent models concerned with the control of visual attention differentiate between goal-directed, top-down and stimulus-driven, bottom-up control, with the former determined by current selection goals and the latter determined by physical salience. In the current review, we discuss recent studies that demonstrate that attentional selection does not need to be the result of top-down or bottom-up processing but, instead, is often driven by lingering biases due to the ``history'' of former attention deployments. This review mainly focuses on reward-based history effects; yet other types of history effects such as (intertrial) priming, statistical learning and affective conditioning are also discussed. We argue that evidence from behavioral, eye-movement and neuroimaging studies supports the idea that selection history modulates the topographical landscape of spatial ``priority'' maps, such that attention is biased toward locations having the highest activation on this map.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/3CK4VRJM/Failing and Theeuwes - 2018 - Selection history How reward modulates selectivit.pdf}
}

@article{fouragnanMacaqueAnteriorCingulate2019a,
  title = {The Macaque Anterior Cingulate Cortex Translates Counterfactual Choice Value into Actual Behavioral Change},
  author = {Fouragnan, E.F. and Chau, B.K.H. and Folloni, D. and Kolling, N. and Verhagen, L. and {Klein-Fl{\"u}gge}, M. and Tankelevitch, L. and Papageorgiou, G.K. and Aubry, J.F. and Sallet, J. and Rushworth, M.F.S},
  year = {2019},
  month = may,
  journal = {Nature Neuroscience},
  volume = {22},
  number = {5},
  pages = {797--808},
  publisher = {{Nature Publishing Group}},
  issn = {1546-1726},
  doi = {10.1038/s41593-019-0375-6},
  abstract = {The neural mechanisms mediating sensory-guided decision-making have received considerable attention, but animals often pursue behaviors for which there is currently no sensory evidence. Such behaviors are guided by internal representations of choice values that have to be maintained even when these choices are unavailable. We investigated how four macaque monkeys maintained representations of the value of counterfactual choices\textemdash choices that could not be taken at the current moment but which could be taken in the future. Using functional magnetic resonance imaging, we found two different patterns of activity co-varying with values of counterfactual choices in a circuit spanning the hippocampus, the anterior lateral prefrontal cortex and the anterior cingulate cortex. Anterior cingulate cortex activity also reflected whether the internal value representations would be translated into actual behavioral change. To establish the causal importance of the anterior cingulate cortex for this translation process, we used a novel technique, transcranial focused ultrasound stimulation, to reversibly disrupt anterior cingulate cortex activity.},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature America, Inc.},
  langid = {english},
  keywords = {Decision,Motivation},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Research Subject\_term: Decision;Motivation Subject\_term\_id: decision;motivation},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/KZC86EJU/Fouragnan et al. - 2019 - The macaque anterior cingulate cortex translates c.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/9L8MVK4G/s41593-019-0375-6.html}
}

@book{foxCompanionAppliedRegression2018,
  title = {An {{R Companion}} to {{Applied Regression}}},
  author = {Fox, J. and Weisberg, S.},
  year = {2018},
  month = sep,
  publisher = {{SAGE Publications}},
  abstract = {An R Companion to Applied Regression is a broad introduction to the R statistical computing environment in the context of applied regression analysis. John Fox and Sanford Weisberg provide a step-by-step guide to using the free statistical software R, an emphasis on integrating statistical computing in R with the practice of data analysis, coverage of generalized linear models, and substantial web-based support materials. The Third Edition includes a new chapter on mixed-effects models, new and updated data sets, and a de-emphasis on statistical programming, while retaining a general introduction to basic R programming. The authors have substantially updated both the car and effects packages for R for this new edition, and include coverage of RStudio and R Markdown.},
  googlebooks = {uPNrDwAAQBAJ},
  isbn = {978-1-5443-3648-0},
  langid = {english},
  keywords = {Reference / Research,Social Science / Statistics}
}

@article{frantiHowMuchCan2019,
  title = {How Much Can K-Means Be Improved by Using Better Initialization and Repeats?},
  author = {Fr{\"a}nti, Pasi and Sieranoja, Sami},
  year = {2019},
  month = sep,
  journal = {Pattern Recognition},
  volume = {93},
  pages = {95--112},
  issn = {0031-3203},
  doi = {10.1016/j.patcog.2019.04.014},
  abstract = {In this paper, we study what are the most important factors that deteriorate the performance of the k-means algorithm, and how much this deterioration can be overcome either by using a better initialization technique, or by repeating (restarting) the algorithm. Our main finding is that when the clusters overlap, k-means can be significantly improved using these two tricks. Simple furthest point heuristic (Maxmin) reduces the number of erroneous clusters from 15\% to 6\%, on average, with our clustering benchmark. Repeating the algorithm 100 times reduces it further down to 1\%. This accuracy is more than enough for most pattern recognition applications. However, when the data has well separated clusters, the performance of k-means depends completely on the goodness of the initialization. Therefore, if high clustering accuracy is needed, a better algorithm should be used instead.},
  langid = {english},
  keywords = {Clustering accuracy,Clustering algorithms,Initialization,K-means,Prototype selection},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/W7674BTD/S0031320319301608.html}
}

@article{fuCounterfactualVisionandLanguageNavigation2020,
  title = {Counterfactual {{Vision-and-Language Navigation}} via {{Adversarial Path Sampling}}},
  author = {Fu, Tsu-Jui and Wang, Xin Eric and Peterson, Matthew and Grafton, Scott and Eckstein, Miguel and Wang, William Yang},
  year = {2020},
  month = jul,
  journal = {arXiv:1911.07308 [cs]},
  eprint = {1911.07308},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Vision-and-Language Navigation (VLN) is a task where agents must decide how to move through a 3D environment to reach a goal by grounding natural language instructions to the visual surroundings. One of the problems of the VLN task is data scarcity since it is difficult to collect enough navigation paths with human-annotated instructions for interactive environments. In this paper, we explore the use of counterfactual thinking as a human-inspired data augmentation method that results in robust models. Counterfactual thinking is a concept that describes the human propensity to create possible alternatives to life events that have already occurred. We propose an adversarial-driven counterfactual reasoning model that can consider effective conditions instead of low-quality augmented data. In particular, we present a model-agnostic adversarial path sampler (APS) that learns to sample challenging paths that force the navigator to improve based on the navigation performance. APS also serves to do pre-exploration of unseen environments to strengthen the model's ability to generalize. We evaluate the influence of APS on the performance of different VLN baseline models using the room-to-room dataset (R2R). The results show that the adversarial training process with our proposed APS benefits VLN models under both seen and unseen environments. And the pre-exploration process can further gain additional improvements under unseen environments.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Computer Vision and Pattern Recognition},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/DK477J3Y/Fu et al. - 2020 - Counterfactual Vision-and-Language Navigation via .pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/VM9XEWQC/1911.html}
}

@article{garnerIncentiveValueSpatial2021a,
  title = {Incentive Value and Spatial Certainty Combine Additively to Determine Visual Priorities},
  author = {Garner, K.G. and Bowman, H. and Raymond, J.E.},
  year = {2021},
  month = jan,
  journal = {Attention, Perception, \& Psychophysics},
  volume = {83},
  number = {1},
  pages = {173--186},
  issn = {1943-393X},
  doi = {10.3758/s13414-020-02124-w},
  abstract = {How does the brain combine information predictive of the value of a visually guided task (incentive value) with information predictive of where task-relevant stimuli may occur (spatial certainty)? Human behavioural evidence indicates that these two predictions may be combined additively to bias visual selection (Additive Hypothesis), whereas neuroeconomic studies posit that they may be multiplicatively combined (Expected Value Hypothesis). We sought to adjudicate between these two alternatives. Participants viewed two coloured placeholders that specified the potential value of correctly identifying an imminent letter target if it appeared in that placeholder. Then, prior to the target's presentation, an endogenous spatial cue was presented indicating the target's more likely location. Spatial cues were parametrically manipulated with regard to the information gained (in bits). Across two experiments, performance was better for targets appearing in high versus low value placeholders and better when targets appeared in validly cued locations. Interestingly, as shown with a Bayesian model selection approach, these effects did not interact, clearly supporting the Additive Hypothesis. Even when conditions were adjusted to increase the optimality of a multiplicative operation, support for it remained. These findings refute recent theories that expected value computations are the singular mechanism driving the deployment of endogenous spatial attention. Instead, incentive value and spatial certainty seem to act independently to influence visual selection.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/D33K2LZS/Garner et al. - 2021 - Incentive value and spatial certainty combine addi.pdf}
}

@book{hairMultivariateDataAnalysis2010,
  title = {Multivariate {{Data Analysis}}: {{A Global Perspective}}},
  shorttitle = {Multivariate {{Data Analysis}}},
  author = {Hair, J.F. and Black, W.C. and Babin, B.J.},
  year = {2010},
  publisher = {{Pearson Education}},
  abstract = {For graduate and upper-level undergraduate marketing research courses. For over 30 years, this text has provided students with the information they need to understand and apply multivariate data analysis. Hair et. al provides an applications-oriented introduction to multivariate analysis for the non-statistician. By reducing heavy statistical research into fundamental concepts, the text explains to students how to understand and make use of the results of specific statistical techniques. In this seventh revision, the organization of the chapters has been greatly simplified. New chapters have been added on structural equations modeling, and all sections have been updated to reflect advances in technology, capability, and mathematical techniques},
  googlebooks = {SLRPLgAACAAJ},
  isbn = {978-0-13-515309-3},
  langid = {english}
}

@article{heyselaarStructuralPrimingSupported2021,
  title = {Structural Priming Is Supported by Different Components of Nondeclarative Memory: {{Evidence}} from Priming across the Lifespan.},
  author = {Heyselaar, Evelien and Wheeldon, Linda and Segaert, Katrien},
  year = {2021},
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  volume = {47},
  number = {5},
  pages = {820--837},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1285(Electronic),0278-7393(Print)},
  doi = {10.1037/xlm0000955},
  abstract = {Structural priming is the tendency to repeat syntactic structure across sentences and can be divided into short-term (prime to immediately following target) and long-term (across an experimental session) components. This study investigates how nondeclarative memory could support both the transient, short-term and the persistent, long-term structural priming effects commonly seen in the literature. We propose that these characteristics are supported by different subcomponents of nondeclarative memory: Perceptual and conceptual nondeclarative memory respectively. Previous studies have suggested that these subcomponents age differently, with only conceptual memory showing age-related decline. By investigating how different components of structural priming vary across the life span, we aim to elucidate how nondeclarative memory supports 2 seemingly different components of structural priming. In 167 participants ranging between 20 and 85 years old, we find no change in short-term priming magnitude and performance on perceptual tasks, whereas both long-term priming and conceptual memory vary with age. We suggest therefore that the 2 seemingly different components of structural priming are supported by different components of nondeclarative memory. These findings have important implications for theoretical accounts of structural priming. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {*Aging,*Long Term Memory,*Priming,*Short Term Memory,Age Differences,Explicit Memory,Life Span,Syntax,Test Construction}
}

@article{hickRateGainInformation1952,
  title = {On the {{Rate}} of {{Gain}} of {{Information}}},
  author = {Hick, W. E.},
  year = {1952},
  month = mar,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {4},
  number = {1},
  pages = {11--26},
  publisher = {{SAGE Publications}},
  issn = {0033-555X},
  doi = {10.1080/17470215208416600},
  abstract = {The analytical methods of information theory are applied to the data obtained in certain choice-reaction-time experiments. Two types of experiment were performed: (a) a conventional choice-reaction experiment, with various numbers of alternatives up to ten, and with a negligible proportion of errors, and (b) a ten-choice experiment in which the subjects deliberately reduced their reaction time by allowing themselves various proportions of errors., The principal finding is that the rate of gain of information is, on the average, constant with respect to time, within the duration of one perceptual-motor act, and has a value of the order of five ``bits'' per second., The distribution of reaction times among the ten stimuli in the second experiment is shown to be related to the objective uncertainty as to which response will be given to each stimulus. The distribution of reaction times among the responses is also related to the same uncertainty. This is further evidence that information is intimately concerned with reaction time., Some possible conceptual models of the process are considered, but tests against the data are inconclusive.},
  langid = {english}
}

@article{hofmansAddedValueBootstrap2015,
  title = {On the {{Added Value}} of {{Bootstrap Analysis}} for {{K-Means Clustering}}},
  author = {Hofmans, J. and Ceulemans, E. and Steinley, D. and Van Mechelen, I.},
  year = {2015},
  month = jul,
  journal = {Journal of Classification},
  volume = {32},
  number = {2},
  pages = {268--284},
  issn = {1432-1343},
  doi = {10.1007/s00357-015-9178-y},
  abstract = {Because of its deterministic nature, K-means does not yield confidence information about centroids and estimated cluster memberships, although this could be useful for inferential purposes. In this paper we propose to arrive at such information by means of a non-parametric bootstrap procedure, the performance of which is tested in an extensive simulation study. Results show that the coverage of hyper-ellipsoid bootstrap confidence regions for the centroids is in general close to the nominal coverage probability. For the cluster memberships, we found that probabilistic membership information derived from the bootstrap analysis can be used to improve the cluster assignment of individual objects, albeit only in the case of a very large number of clusters. However, in the case of smaller numbers of clusters, the probabilistic membership information still appeared to be useful as it indicates for which objects the cluster assignment resulting from the analysis of the original data is likely to be correct; hence, this information can be used to construct a partial clustering in which the latter objects only are assigned to clusters.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/HIBS4UHJ/Hofmans et al. - 2015 - On the Added Value of Bootstrap Analysis for K-Mea.pdf}
}

@article{huangFVSUnifyingFramework2021,
  title = {{{FVS}} 2.0: {{A}} Unifying Framework for Understanding the Factors of Visual-Attentional Processing},
  shorttitle = {{{FVS}} 2.0},
  author = {Huang, Liqiang},
  year = {2021},
  journal = {Psychological Review},
  pages = {No Pagination Specified-No Pagination Specified},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471(Electronic),0033-295X(Print)},
  doi = {10.1037/rev0000314},
  abstract = {Across a broad range of stimulus types and tasks (16 stimulus types \texttimes{} 26 tasks, 1,744 observers in total), the present study employed an individual-item differences analysis to extract the factors of visual-attentional processing. Three orthogonal factors were identified and they can be summarized as an FVS 2.0 framework: featural, visual, and spatial strengths. Apart from one exception (low-level motion), the FVS 2.0 framework accounts for the vast majority (95.4\%) of the variances in the 25 tasks. Therefore, the three straightforward factors provide a unifying framework for understanding the relationship between stimulus types as well as those between tasks. Combining these and other related results, the role of preattentive features seems to be rather different from the traditional view: visual features are general purpose, exclusive, innate, constancy based, and keyword like. A general-purpose, exclusive, innate, constancy-based and keyword-like (GEICK) conjecture is proposed which suggests that the features are conscious-level keywords generated by the specific brain area of V4 and/or IT and then used by all other brain areas. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Short Term Memory,Visual Attention,Visual Memory,Visual Perception},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/MJL58RBQ/Huang - 2021 - FVS 2.0 A unifying framework for understanding th.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/9JC7PCAR/2021-67316-001.html}
}

@article{hutchinsonMemoryguidedAttentionControl2012,
  title = {Memory-Guided Attention: {{Control}} from Multiple Memory Systems},
  shorttitle = {Memory-Guided Attention},
  author = {Hutchinson, J. Benjamin and {Turk-Browne}, Nicholas B.},
  year = {2012},
  month = dec,
  journal = {Trends in cognitive sciences},
  volume = {16},
  number = {12},
  pages = {576--579},
  issn = {1364-6613},
  doi = {10.1016/j.tics.2012.10.003},
  abstract = {Attention is strongly influenced by both external stimuli and internal goals. However, this useful dichotomy does not readily capture the ubiquitous and often automatic contribution of past experience stored in memory. We review recent evidence about how multiple memory systems control attention, consider how such interactions are manifested in the brain, and highlight how this framework for `memory-guided attention' might help systematize previous findings and guide future research.},
  pmcid = {PMC3728770},
  pmid = {23141429},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/D8ACP7QC/Hutchinson and Turk-Browne - 2012 - Memory-guided attention Control from multiple mem.pdf}
}

@article{hymanStimulusInformationDeterminant1953,
  title = {Stimulus Information as a Determinant of Reaction Time.},
  author = {Hyman, R.},
  year = {1953},
  journal = {Journal of experimental psychology},
  doi = {10.1037/H0056940},
  abstract = {In the typical reaction-time experiment, S's reaction time is greater when he has to respond differentially to one of two equally probable stimuli instead of to just one stimulus, but this becomes even more significant when looked at from the standpoint of modern communication theory. In the typical reaction-time experiment, S's reaction time is greater when he has to respond differentially to one of two equally probable stimuli instead of to just one stimulus. In fact, Merkel (2), using one to ten alternatives, has demonstrated that when S has to respond to one stimulus chosen from a number of equally probable alternatives, his reaction time increases with the number of alternatives. The fact that S's response to stimulus A takes more time when A is one of several rather than one of two equally probable alternatives is of intrinsic interest. But it becomes even more significant when looked at from the standpoint of modern communication theory. In communication theory the amount of information which a message conveys is an increasing function of the number of possible messages from which that particular message could have been selected. The S's reaction time seems to behave,}
}

@article{itthipuripatValuedrivenAttentionalCapture2019,
  title = {Value-Driven Attentional Capture Enhances Distractor Representations in Early Visual Cortex},
  author = {Itthipuripat, S. and Vo, Vy A. and Sprague, T.C. and Serences, J.T.},
  year = {2019},
  month = aug,
  journal = {PLOS Biology},
  volume = {17},
  number = {8},
  pages = {e3000186},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.3000186},
  abstract = {When a behaviorally relevant stimulus has been previously associated with reward, behavioral responses are faster and more accurate compared to equally relevant but less valuable stimuli. Conversely, task-irrelevant stimuli that were previously associated with a high reward can capture attention and distract processing away from relevant stimuli (e.g., seeing a chocolate bar in the pantry when you are looking for a nice, healthy apple). Although increasing the value of task-relevant stimuli systematically up-regulates neural responses in early visual cortex to facilitate information processing, it is not clear whether the value of task-irrelevant distractors influences behavior via competition in early visual cortex or via competition at later stages of decision-making and response selection. Here, we measured functional magnetic resonance imaging (fMRI) in human visual cortex while subjects performed a value-based learning task, and we applied a multivariate inverted encoding model (IEM) to assess the fidelity of distractor representations in early visual cortex. We found that the fidelity of neural representations related to task-irrelevant distractors increased when the distractors were previously associated with a high reward. This finding suggests that value-driven attentional capture begins with sensory modulations of distractor representations in early areas of visual cortex.},
  langid = {english},
  keywords = {Color vision,Decision making,Functional magnetic resonance imaging,Learning,Sensory perception,Vision,Visual cortex,Visual system},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/T2AK33FL/Itthipuripat et al. - 2019 - Value-driven attentional capture enhances distract.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/5A3TV5CE/article.html}
}

@article{ittiComputationalModellingVisual2001,
  title = {Computational Modelling of Visual Attention},
  author = {Itti, L and Koch, C},
  year = {2001},
  month = mar,
  journal = {Nature Reviews Neuroscience},
  volume = {2},
  number = {3},
  pages = {194--203},
  publisher = {{Nature Publishing Group}},
  issn = {1471-0048},
  doi = {10.1038/35058500},
  abstract = {We review recent work on computational models of focal visual attention, with emphasis on the bottom-up, saliency- or image-based control of attentional deployment. We highlight five important trends that have emerged from the computational literature: First, the perceptual saliency of stimuli critically depends on surrounding context; that is, the same object may or may not appear salient depending on the nature and arrangement of other objects in the scene. Computationally, this means that contextual influences, such as non-classical surround interactions, must be included in models. Second, a unique 'saliency map' topographically encoding for stimulus conspicuity over the visual scene has proved to be an efficient and plausible bottom-up control strategy. Many successful models are based on such architecture, and electrophysiological as well as psychophysical studies have recently supported the idea that saliency is explicitly encoded in the brain. Third, inhibition-of-return (IOR), the process by which the currently attended location is transiently inhibited, is a critical element of attentional deployment. Without IOR, attention would endlessly be attracted towards the most salient stimulus. IOR thus implements a memory of recently visited locations, and allows attention to thoroughly scan our visual environment. Fourth, attention and eye movements tightly interplay, posing computational challenges with respect to the coordinate system used to control attention. Understanding the interaction between overt and covert attention is particularly important for models concerned with visual search. Last, scene understanding and object recognition strongly constrain the selection of attended locations. Although several models have approached, in an information-theoretical sense, the problem of optimally deploying attention to analyse a scene, biologically plausible implementations of such a computational strategy remain to be developed.},
  copyright = {2001 Nature Publishing Group},
  langid = {english},
  annotation = {Bandiera\_abtest: a Cg\_type: Nature Research Journals Primary\_atype: Reviews},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/KFSJ4L3X/Itti and Koch - 2001 - Computational modelling of visual attention.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/EAR4NTVQ/35058500.html}
}

@article{ittiSaliencybasedSearchMechanism2000,
  title = {A Saliency-Based Search Mechanism for Overt and Covert Shifts of Visual Attention},
  author = {Itti, L. and Koch, C.},
  year = {2000},
  month = jun,
  journal = {Vision Research},
  volume = {40},
  number = {10},
  pages = {1489--1506},
  issn = {0042-6989},
  doi = {10.1016/S0042-6989(99)00163-7},
  abstract = {Most models of visual search, whether involving overt eye movements or covert shifts of attention, are based on the concept of a saliency map, that is, an explicit two-dimensional map that encodes the saliency or conspicuity of objects in the visual environment. Competition among neurons in this map gives rise to a single winning location that corresponds to the next attended target. Inhibiting this location automatically allows the system to attend to the next most salient location. We describe a detailed computer implementation of such a scheme, focusing on the problem of combining information across modalities, here orientation, intensity and color information, in a purely stimulus-driven manner. The model is applied to common psychophysical stimuli as well as to a very demanding visual search task. Its successful performance is used to address the extent to which the primate visual system carries out visual search via one or more such saliency maps and how this can be tested.},
  langid = {english},
  keywords = {Saliency,Vision systems,Visual attention},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/GYP5A3VF/Itti and Koch - 2000 - A saliency-based search mechanism for overt and co.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/VVL4NUDM/S0042698999001637.html}
}

@article{jiangHabitlikeAttention2019,
  title = {Habit-like Attention},
  author = {Jiang, Y.V. and Sisk, C.A.},
  year = {2019},
  month = oct,
  journal = {Current Opinion in Psychology},
  series = {Attention \& {{Perception}}},
  volume = {29},
  pages = {65--70},
  issn = {2352-250X},
  doi = {10.1016/j.copsyc.2018.11.014},
  abstract = {The control of selective attention is traditionally considered to be either goal-driven or stimulus-driven. Increasing research, however, has linked past experience to attentional selection. Effects of selection history may be transient, as in inter-trial priming, or durable. Here we review several examples of enduring changes of attention and relate them to properties of habits. Like motor habits, reading direction is reinforced over an extended period of time. Despite the brevity of training, probability learning, context learning, value-driven attention, and learned attentional set also exhibit habit-like properties, including automaticity, insensitivity to outcome devaluation, and inflexibility. A consideration of whether a selection history effect is habit-like may help taxonomize diverse forms of experience-driven attention.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/N5TMZMB8/Jiang and Sisk - 2019 - Habit-like attention.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/QWRV6CNL/S2352250X18301738.html}
}

@article{jiangHabitualGoaldrivenAttention2018,
  title = {Habitual versus Goal-Driven Attention},
  author = {Jiang, Yuhong V.},
  year = {2018},
  month = may,
  journal = {Cortex},
  series = {The {{Unconscious Guidance}} of {{Attention}}},
  volume = {102},
  pages = {107--120},
  issn = {0010-9452},
  doi = {10.1016/j.cortex.2017.06.018},
  abstract = {Recent research has expanded the list of factors that control spatial attention. Beside current goals and perceptual salience, statistical learning, reward, motivation and emotion also affect attention. But do these various factors influence spatial attention in the same manner, as suggested by the integrated framework of attention, or do they target different aspects of spatial attention? Here I present evidence that the control of attention may be implemented in two ways. Whereas current goals typically modulate where in space attention is prioritized, search habits affect how one moves attention in space. Using the location probability learning paradigm, I show that a search habit forms when people frequently find a visual search target in one region of space. Attentional cuing by probability learning differs from that by current goals. Probability cuing is implicit and persists long after the probability cue is no longer valid. Whereas explicit goal-driven attention codes space in an environment-centered reference frame, probability cuing is viewer-centered and is insensitive to secondary working memory load and aging. I propose a multi-level framework that separates the source of attentional control from its implementation. Similar to the integrated framework, the multi-level framework considers current goals, perceptual salience, and selection history as major sources of attentional control. However, these factors are implemented in two ways, controlling where spatial attention is allocated and how one shifts attention in space.},
  langid = {english},
  keywords = {Implicit learning,Search habit,Spatial attention,Spatial reference frame},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/N2SYZNC8/Jiang - 2018 - Habitual versus goal-driven attention.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/SXEFV3IV/S0010945217302071.html}
}

@article{kasperPhysIOToolboxModeling2017a,
  title = {The {{PhysIO Toolbox}} for {{Modeling Physiological Noise}} in {{fMRI Data}}},
  author = {Kasper, Lars and Bollmann, Steffen and Diaconescu, Andreea O. and Hutton, Chloe and Heinzle, Jakob and Iglesias, Sandra and Hauser, Tobias U. and Sebold, Miriam and Manjaly, Zina-Mary and Pruessmann, Klaas P. and Stephan, Klaas E.},
  year = {2017},
  month = jan,
  journal = {Journal of Neuroscience Methods},
  volume = {276},
  pages = {56--72},
  issn = {0165-0270},
  doi = {10.1016/j.jneumeth.2016.10.019},
  abstract = {Background Physiological noise is one of the major confounds for fMRI. A common class of correction methods model noise from peripheral measures, such as ECGs or pneumatic belts. However, physiological noise correction has not emerged as a standard preprocessing step for fMRI data yet due to: (1) the varying data quality of physiological recordings, (2) non-standardized peripheral data formats and (3) the lack of full automatization of processing and modeling physiology, required for large-cohort studies. New methods We introduce the PhysIO Toolbox for preprocessing of physiological recordings and model-based noise correction. It implements a variety of noise models, such as RETROICOR, respiratory volume per time and heart rate variability responses (RVT/HRV). The toolbox covers all intermediate steps - from flexible read-in of data formats to GLM regressor/contrast creation - without any manual intervention. Results We demonstrate the workflow of the toolbox and its functionality for datasets from different vendors, recording devices, field strengths and subject populations. Automatization of physiological noise correction and performance evaluation are reported in a group study (N=35). Comparison with existing methods The PhysIO Toolbox reproduces physiological noise patterns and correction efficacy of previously implemented noise models. It increases modeling robustness by outperforming vendor-provided peak detection methods for physiological cycles. Finally, the toolbox offers an integrated framework with full automatization, including performance monitoring, and flexibility with respect to the input data. Conclusions Through its platform-independent Matlab implementation, open-source distribution, and modular structure, the PhysIO Toolbox renders physiological noise correction an accessible preprocessing step for fMRI data.},
  langid = {english},
  keywords = {fMRI,fMRI preprocessing,Heart rate,Physiological noise correction,Respiratory volume,RETROICOR,RVHRCOR,SPM toolbox},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/V65QMK7H/Kasper et al. - 2017 - The PhysIO Toolbox for Modeling Physiological Nois.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/D7BLEFKG/S016502701630259X.html}
}

@article{kimCombinedInfluenceValence2021,
  title = {Combined Influence of Valence and Statistical Learning on the Control of Attention: {{Evidence}} for Independent Sources of Bias},
  shorttitle = {Combined Influence of Valence and Statistical Learning on the Control of Attention},
  author = {Kim, Haena and Anderson, Brian A.},
  year = {2021},
  month = mar,
  journal = {Cognition},
  volume = {208},
  pages = {104554},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2020.104554},
  abstract = {Selection history exerts a powerful influence on the control of attention. Stimuli signalling reward and punishment capture attention even when physically non-salient and task-irrelevant. Repeated presentation of a salient distractor at a particular location generates learned suppression, resulting in reduced attentional processing at that location. A debate in the field concerns whether different components of selection history influence attention via a common underlying mechanism of learning-dependent control or via distinct, independent mechanisms. We probed this question with a particular focus on reward/punishment history and learned suppression. Participants were trained to suppress a particular location (high probability distractor location) and associate colours with reward or no outcome (no-reward). In a subsequent task, reward and no-reward distractors appeared in all locations equally often. In a separate experiment, we replaced reward with electric shocks. Reward and shock distractors captured attention more strongly than no-reward and no-shock distractors irrespective of their location. Distractors appearing in the high probability location showed reduced capture irrespective of their type. The results imply that reward and punishment learning and learned suppression have independent influences on the attentional system.},
  langid = {english},
  keywords = {Aversive conditioning,Reward learning,Selection history,Selective attention,Statistical learning},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/B26LSZWJ/S0010027720303735.html}
}

@article{koolLaborLeisureTradeoff2014,
  title = {A Labor/Leisure Tradeoff in Cognitive Control},
  author = {Kool, Wouter and Botvinick, Matthew},
  year = {2014},
  journal = {Motivation Science},
  volume = {1},
  number = {S},
  pages = {3--18},
  publisher = {{Educational Publishing Foundation}},
  address = {{US}},
  issn = {2333-8121(Electronic),2333-8113(Print)},
  doi = {10.1037/2333-8113.1.S.3},
  abstract = {Daily life frequently offers a choice between activities that are profitable but mentally demanding (cognitive labor) and activities that are undemanding but also unproductive (cognitive leisure). Although such decisions are often implicit, they help determine academic performance, career trajectories, and even health outcomes. Previous research has shed light both on the executive control functions that ultimately define cognitive labor and on a ``default mode'' of brain function that accompanies cognitive leisure. However, little is known about how labor/leisure decisions are actually made. Here, we identify a central principle guiding such decisions. Results from 3 economic-choice experiments indicate that the motivation underlying cognitive labor/leisure decision making is to strike an optimal balance between income and leisure, as given by a joint utility function. The results reported establish a new connection between microeconomics and research on executive function. They also suggest a new interpretation of so-called ego-depletion effects and a potential new approach to such phenomena as mind wandering and self-control failure. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Behavioral Economics,Cognitive Control,Decision Making,Energy Expenditure},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/Z5V7L5UG/Kool and Botvinick - 2014 - A laborleisure tradeoff in cognitive control.pdf}
}

@article{lanthierResolvingControversyProportion2015,
  title = {Resolving the Controversy of the Proportion Validity Effect: {{Volitional}} Attention Is Not Required, but May Have an Effect},
  shorttitle = {Resolving the Controversy of the Proportion Validity Effect},
  author = {Lanthier, S.N. and Wu, D.W.L. and Chapman, C.S. and Kingstone, A.},
  year = {2015},
  month = nov,
  journal = {Attention, Perception, \& Psychophysics},
  volume = {77},
  number = {8},
  pages = {2611--2621},
  issn = {1943-393X},
  doi = {10.3758/s13414-015-0956-8},
  abstract = {Response time (RT) is facilitated when a target appears at a cued (valid) location versus an uncued (invalid) location. Interestingly, this valid-versus-invalid RT difference increases as the percentage of valid trials increases. In the present study, we investigated the mechanism responsible for this proportion valid cueing effect (PVE). The PVE is thought to reflect changes in voluntary attentional allocation, with greater attention being committed endogenously to the cued location as the percentage of valid trials increases. However, recent research has suggested that the PVE may reflect a form of implicit learning between the cue and the target location that is developed outside of awareness, and that this determines how attention is allocated. This lack of convergence may be due to methodological differences in how voluntary processing has been inferred. To test this issue, we generated a method that would allow the measurement of different degrees of volitional attention. In addition, we manipulated whether participants were instructed to attend to the cue\textendash target relationship and determined whether this explicit engagement of attention influenced the PVE. We found that for both peripheral and central cues, volitional control is not required for a PVE; however, volitional control can modulate a PVE that is produced by central cues. Thus, a PVE is not a reliable indicator of volitional control, but its sensitivity to volitional control varies across cues. The present data shed light on the mechanism subserving the PVE and lend support to the theory that different cues engage, to some degree, qualitatively different forms of visuospatial attention.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/KCQYPR5A/Lanthier et al. - 2015 - Resolving the controversy of the proportion validi.pdf}
}

@article{lepelleyAttentionAssociativeLearning2016a,
  title = {Attention and Associative Learning in Humans: {{An}} Integrative Review},
  shorttitle = {Attention and Associative Learning in Humans},
  author = {Le Pelley, M.E. and Mitchell, C.J. and Beesley, T. and George, D.N. and Wills, A.J.},
  year = {2016},
  journal = {Psychological Bulletin},
  volume = {142},
  number = {10},
  pages = {1111--1140},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1455},
  doi = {10.1037/bul0000064},
  abstract = {This article presents a comprehensive survey of research concerning interactions between associative learning and attention in humans. Four main findings are described. First, attention is biased toward stimuli that predict their consequences reliably (learned predictiveness). This finding is consistent with the approach taken by Mackintosh (1975) in his attentional model of associative learning in nonhuman animals. Second, the strength of this attentional bias is modulated by the value of the outcome (learned value). That is, predictors of high-value outcomes receive especially high levels of attention. Third, the related but opposing idea that uncertainty may result in increased attention to stimuli (Pearce \& Hall, 1980), receives less support. This suggests that hybrid models of associative learning, incorporating the mechanisms of both the Mackintosh and Pearce-Hall theories, may not be required to explain data from human participants. Rather, a simpler model, in which attention to stimuli is determined by how strongly they are associated with significant outcomes, goes a long way to account for the data on human attentional learning. The last main finding, and an exciting area for future research and theorizing, is that learned predictiveness and learned value modulate both deliberate attentional focus, and more automatic attentional capture. The automatic influence of learning on attention does not appear to fit the traditional view of attention as being either goal-directed or stimulus-driven. Rather, it suggests a new kind of ``derived'' attention. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Associative Processes,Attention,Conditioning,Learning,Reward Learning,Rewards},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/A2Z7FIYE/Le Pelley et al. - 2016 - Attention and associative learning in humans An i.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/EIXD29TW/2016-37454-001.html}
}

@article{lepelleyRewardLearningStatistical2022,
  title = {Reward Learning and Statistical Learning Independently Influence Attentional Priority of Salient Distractors in Visual Search},
  author = {Le Pelley, Mike E. and Ung, Rhonda and Mine, Chisato and Most, Steven B. and Watson, Poppy and Pearson, Daniel and Theeuwes, Jan},
  year = {2022},
  month = jan,
  journal = {Attention, Perception \& Psychophysics},
  issn = {1943-393X},
  doi = {10.3758/s13414-021-02426-7},
  abstract = {Existing research demonstrates different ways in which attentional prioritization of salient nontarget stimuli is shaped by prior experience: Reward learning renders signals of high-value outcomes more likely to capture attention than signals of low-value outcomes, whereas statistical learning can produce attentional suppression of the location in which salient distractor items are likely to appear. The current study combined manipulations of the value and location associated with salient distractors in visual search to investigate whether these different effects of selection history operate independently or interact to determine overall attentional prioritization of salient distractors. In Experiment 1, high-value and low-value distractors most frequently appeared in the same location; in Experiment 2, high-value and low-value distractors typically appeared in distinct locations. In both experiments, effects of distractor value and location were additive, suggesting that attention-promoting effects of value and attention-suppressing effects of statistical location-learning independently modulate overall attentional priority. Our findings are consistent with a view that sees attention as mediated by a common priority map that receives and integrates separate signals relating to physical salience and value, with signal suppression based on statistical learning determined by physical salience, but not incentive salience.},
  langid = {english},
  pmcid = {PMC8747445},
  pmid = {35013993},
  keywords = {Attention,Reward,Statistical learning,Suppression,Visual search},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/3JXNCTNJ/Le Pelley et al. - 2022 - Reward learning and statistical learning independe.pdf}
}

@article{lepelleyWhenGoalsConflict2015,
  title = {When Goals Conflict with Values: {{Counterproductive}} Attentional and Oculomotor Capture by Reward-Related Stimuli},
  shorttitle = {When Goals Conflict with Values},
  author = {Le Pelley, M.E. and Pearson, D. and Griffiths, O. and Beesley, T.},
  year = {2015},
  journal = {Journal of Experimental Psychology: General},
  volume = {144},
  number = {1},
  pages = {158--171},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-2222},
  doi = {10.1037/xge0000037},
  abstract = {Attention provides the gateway to cognition, by selecting certain stimuli for further analysis. Recent research demonstrates that whether a stimulus captures attention is not determined solely by its physical properties, but is malleable, being influenced by our previous experience of rewards obtained by attending to that stimulus. Here we show that this influence of reward learning on attention extends to task-irrelevant stimuli. In a visual search task, certain stimuli signaled the magnitude of available reward, but reward delivery was not contingent on responding to those stimuli. Indeed, any attentional capture by these critical distractor stimuli led to a reduction in the reward obtained. Nevertheless, distractors signaling large reward produced greater attentional and oculomotor capture than those signaling small reward. This counterproductive capture by task-irrelevant stimuli is important because it demonstrates how external reward structures can produce patterns of behavior that conflict with task demands, and similar processes may underlie problematic behavior directed toward real-world rewards. (PsycInfo Database Record (c) 2020 APA, all rights reserved)},
  keywords = {Attentional Capture,Eye Movements,Learning,Reinforcement,Reward Learning,Rewards,Visual Attention,Visual Search},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/QJZRMIMN/2014-49925-001.html}
}

@incollection{lingawiPsychologicalPhysiologicalMechanisms2016,
  title = {The Psychological and Physiological Mechanisms of Habit Formation},
  booktitle = {The {{Wiley}} Handbook on the Cognitive Neuroscience of Learning},
  author = {Lingawi, N.W. and Dezfouli, A. and Balleine, B.W.},
  year = {2016},
  series = {Wiley Handbooks in Cognitive Neuroscience},
  pages = {411--441},
  publisher = {{Wiley-Blackwell}},
  abstract = {In recent years, there has been a growing body of research aimed at elucidating the psychological factors and neural substrates of habitual behavior. Attaining a better understanding of these factors not only provides us with greater knowledge of our own overt actions, but provides an insight into the way we adapt to a changing environment. As a result, in this chapter, we will discuss how we study habitual behavior empirically as well as the psychological and neural mechanisms of habit development. Finally, we will discuss how habits interact with non-habitual actions and the structure in which actions are selected. (PsycINFO Database Record (c) 2017 APA, all rights reserved)},
  isbn = {978-1-118-65094-3 978-1-118-65085-1 978-1-118-65084-4},
  keywords = {Habits,Neurons,Physiological Correlates,Psychodynamics},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/X78QYJM2/2016-25402-016.html}
}

@article{mackintoshTheoryAttentionVariations1975,
  title = {A Theory of Attention: {{Variations}} in the Associability of Stimuli with Reinforcement},
  shorttitle = {A Theory of Attention},
  author = {Mackintosh, N. J.},
  year = {1975},
  journal = {Psychological Review},
  volume = {82},
  number = {4},
  pages = {276--298},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1471},
  doi = {10.1037/h0076778},
  abstract = {Review of the literature indicates that, according to theories of selective attention, learning about a stimulus depends on attending to that stimulus; this is represented in 2-stage models by saying that Ss switch in analyzers as well as learning stimulus-response associations. It is argued that this assumption, however, is equally well represented in a formal model by the incorporation of a stimulus-specific learning-rate parameter, a, into the equations describing changes in the associative strength of stimuli. Previous theories of selective attention have also assumed that (a) Ss learn to attend to and ignore relevant and irrelevant stimuli (i.e., that a may increase or decrease depending on the correlation of a stimulus with reinforcement); and (b) there is an inverse relationship between the probabilities of attending to different stimuli (i.e., that an increase in a to one stimulus is accompanied by a decrease in a to others). The first assumption has been used to explain the phenomena of acquired distinctiveness and dimensional transfer, the second to explain those of overshadowing and blocking. It is argued that although the first assumption is justified by the data, the second is not: Overshadowing and blocking are better explained by the choice of an appropriate rule for changing a, such that a decreases to stimuli that signal no change from the probability of reinforcement predicted by other stimuli. (65 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  keywords = {Associative Processes,Learning Rate,Learning Theory,Reinforcement,Selective Attention},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/TNWWN8YY/1975-26802-001.html}
}

@article{macleanIrrelevantLearnedReward2016,
  title = {Irrelevant Learned Reward Associations Disrupt Voluntary Spatial Attention},
  author = {MacLean, M.H. and Diaz, G.K. and Giesbrecht, B.},
  year = {2016},
  month = oct,
  journal = {Attention, Perception, \& Psychophysics},
  volume = {78},
  number = {7},
  pages = {2241--2252},
  issn = {1943-393X},
  doi = {10.3758/s13414-016-1103-x},
  abstract = {Attention can be guided involuntarily by physical salience and by non-salient, previously learned reward associations that are currently task-irrelevant. Attention can be guided voluntarily by current goals and expectations. The current study examined, in two experiments, whether irrelevant reward associations could disrupt current, goal-driven, voluntary attention. In a letter-search task, attention was directed voluntarily (i.e., cued) on half the trials by a cue stimulus indicating the hemifield in which the target letter would appear with 100 \% accuracy. On the other half of the trials, a cue stimulus was presented, but it did not provide information about the target hemifield (i.e., uncued). On both cued and uncued trials, attention could be involuntarily captured by the presence of a task-irrelevant, and physically non-salient, color, either within the cued or the uncued hemifield. Importantly, one week prior to the letter search task, the irrelevant color had served as a target feature that was predictive of reward in a separate training task. Target identification accuracy was better on cued compared to uncued trials. However, this effect was reduced when the irrelevant, and physically non-salient, reward-associated feature was present in the uncued hemifield. This effect was not observed in a second, control experiment in which the irrelevant color was not predictive of reward during training. Our results indicate that involuntary, value-driven capture can disrupt the voluntary control of spatial attention.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/CMYJQ2WC/MacLean et al. - 2016 - Irrelevant learned reward associations disrupt vol.pdf}
}

@article{manoharDistinctMotivationalEffects2017,
  title = {Distinct {{Motivational Effects}} of {{Contingent}} and {{Noncontingent Rewards}}},
  author = {Manohar, S.G. and Finzi, R.D. and Drew, D. and Husain, M.},
  year = {2017},
  month = jul,
  journal = {Psychological Science},
  volume = {28},
  number = {7},
  pages = {1016--1026},
  issn = {0956-7976},
  doi = {10.1177/0956797617693326},
  abstract = {When rewards are available, people expend more energy, increasing their motivational vigor. In theory, incentives might drive behavior for two distinct reasons: First, they increase expected reward; second, they increase the difference in subjective value between successful and unsuccessful performance, which increases contingency\textemdash the degree to which action determines outcome. Previous studies of motivational vigor have never compared these directly. Here, we indexed motivational vigor by measuring the speed of eye movements toward a target after participants heard a cue indicating how outcomes would be determined. Eye movements were faster when the cue indicated that monetary rewards would be contingent on performance than when the cue indicated that rewards would be random. But even when the cue indicated that a reward was guaranteed regardless of speed, movement was still faster than when no reward was available. Motivation by contingent and certain rewards was uncorrelated across individuals, which suggests that there are two separable, independent components of motivation. Contingent motivation generated autonomic arousal, and unlike noncontingent motivation, was effective with penalties as well as rewards.},
  pmcid = {PMC5510684},
  pmid = {28488927},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/JMNNPY53/Manohar et al. - 2017 - Distinct Motivational Effects of Contingent and No.pdf}
}

@incollection{maratosChapterWhatDrives2019,
  title = {Chapter 6 - {{What}} Drives Prioritized Visual Processing? {{A}} Motivational Relevance Account},
  shorttitle = {Chapter 6 - {{What}} Drives Prioritized Visual Processing?},
  booktitle = {Progress in {{Brain Research}}},
  author = {Maratos, Frances Anne and Pessoa, Luiz},
  editor = {Srinivasan, Narayanan},
  year = {2019},
  month = jan,
  series = {Emotion and {{Cognition}}},
  volume = {247},
  pages = {111--148},
  publisher = {{Elsevier}},
  doi = {10.1016/bs.pbr.2019.03.028},
  abstract = {Emotion is fundamental to our being, and an essential aspect guiding behavior when rapid responding is required. This includes whether we approach or avoid a stimulus, and the accompanying physiological responses. A common tenet is that threat-related content drives stimulus processing and biases visual attention, so that rapid responding can be initiated. In this paper, it will be argued instead that prioritization of threatening stimuli should be encompassed within a motivational relevance framework. To more fully understand what is, or is not, prioritized for visual processing one must, however, additionally consider: (i) stimulus ambiguity and perceptual saliency; (ii) task demands, including both perceptual load and cognitive load; and (iii) endogenous/affective states of the individual. Combined with motivational relevance, this then leads to a multifactorial approach to understanding the drivers of prioritized visual processing. This accords with current recognition that the brain basis allowing for visual prioritization is also multifactorial, including transient, dynamic and overlapping networks. Taken together, the paper provides a reconceptualization of how ``emotional'' information prioritizes visual processing.},
  langid = {english},
  keywords = {Affect,Brain,Load,Motivational relevance,Prioritization,Stimulus saliency,Threat superiority,Transient networks,Visual attention}
}

@article{massarRewardsBoostSustained2016,
  title = {Rewards Boost Sustained Attention through Higher Effort: {{A}} Value-Based Decision Making Approach},
  shorttitle = {Rewards Boost Sustained Attention through Higher Effort},
  author = {Massar, Stijn A. A. and Lim, Julian and Sasmita, Karen and Chee, Michael W. L.},
  year = {2016},
  month = oct,
  journal = {Biological Psychology},
  volume = {120},
  pages = {21--27},
  issn = {0301-0511},
  doi = {10.1016/j.biopsycho.2016.07.019},
  abstract = {Maintaining sustained attention over time is an effortful process limited by finite cognitive resources. Recent theories describe the role of motivation in the allocation of such resources as a decision process: the costs of effortful performance are weighed against its gains. We examined this hypothesis by combining methods from attention research and decision neuroscience. Participants first performed a sustained attention task at different levels of reward. They then performed a reward-discounting task, measuring the subjective costs of performance. Results demonstrated that higher rewards led to improved performance (Exp 1\textendash 3), and enhanced attentional effort (i.e. pupil diameter; Exp 2 \& 3). Moreover, discounting curves constructed from the choice task indicated that subjects devalued rewards that came at the cost of staying vigilant for a longer duration (Exp 1 \& 2). Motivation can thus boost sustained attention through increased effort, while sustained performance is regarded as a cost against which rewards are discounted.},
  langid = {english},
  keywords = {Decision making,Effort-discounting,Pupillometry,Reward motivation,Sustained attention},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/PMWFXET2/S0301051116302526.html}
}

@article{mattlerCombinedExpectancyEffects2004,
  title = {Combined Expectancy Effects Are Modulated by the Relation between Expectancy Cues},
  author = {Mattler, Uwe},
  year = {2004},
  journal = {The Quarterly Journal of Experimental Psychology A: Human Experimental Psychology},
  volume = {57A},
  number = {2},
  pages = {193--221},
  publisher = {{Taylor \& Francis}},
  address = {{United Kingdom}},
  issn = {1464-0740},
  doi = {10.1080/02724980343000161},
  abstract = {Studies of combined expectancies have shown that spatial cueing effects are reduced on trials on which participants have to respond with an unexpected motor response. In the first two experiments the range of reduced expectancy effects is examined. Advance knowledge of the likely response was combined in a trial-by-trial procedure with modality cueing, object cueing, and task cueing. Effects of modality cueing were reduced on trials on which the target requested an unexpected response. However, effects of object cueing as well as effects of task cueing were unaffected by response cueing. Comparing experiments revealed that different types of cues were used in different experiments. To test the effect of type of cue on the interaction of expectancies the third experiment combined spatial cueing with response cueing. When integrated cues were used that cued the likely target location by an arrow and the likely response by an arrow too, spatial cueing effects were reduced on trials with unexpected responses. However, spatial cueing effects remained unaffected by response cueing when separated cues were used consisting in a word cueing the response and an arrow cueing target location... (PsycINFO Database Record (c) 2018 APA, all rights reserved)},
  keywords = {Cues,Expectations,Motor Processes,Perceptual Motor Coordination,Responses},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/36LX6GQY/2004-10393-001.html}
}

@article{mooreNeuralMechanismsSelective2017,
  title = {Neural {{Mechanisms}} of {{Selective Visual Attention}}},
  author = {Moore, T. and Zirnsak, M.},
  year = {2017},
  journal = {Annual Review of Psychology},
  volume = {68},
  number = {1},
  pages = {47--72},
  doi = {10.1146/annurev-psych-122414-033400},
  abstract = {Selective visual attention describes the tendency of visual processing to be confined largely to stimuli that are relevant to behavior. It is among the most fundamental of cognitive functions, particularly in humans and other primates for whom vision is the dominant sense. We review recent progress in identifying the neural mechanisms of selective visual attention. We discuss evidence from studies of different varieties of selective attention and examine how these varieties alter the processing of stimuli by neurons within the visual system, current knowledge of their causal basis, and methods for assessing attentional dysfunctions. In addition, we identify some key questions that remain in identifying the neural mechanisms that give rise to the selective processing of visual information.},
  pmid = {28051934},
  keywords = {cognition,neural circuits,orienting,sensory processing,visual perception},
  annotation = {\_eprint: https://doi.org/10.1146/annurev-psych-122414-033400}
}

@misc{moreyBayesFactorComputationBayes2015,
  title = {{{BayesFactor}}: {{Computation}} of {{Bayes Factors}} for {{Common Designs}}},
  shorttitle = {{{BayesFactor}}},
  author = {Morey, R.D. and Rouder, J.N. and Jamil, T.},
  year = {2015},
  month = sep,
  abstract = {A suite of functions for computing various Bayes factors for simple designs, including contingency tables, one- and two-sample designs, one-way designs, general ANOVA designs, and linear regression.},
  copyright = {GPL-2},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/GARGXE9J/index.html}
}

@article{mullerRelevanceDrivesAttention2016,
  title = {Relevance Drives Attention: {{Attentional}} Bias for Gain- and Loss-Related Stimuli Is Driven by Delayed Disengagement},
  shorttitle = {Relevance Drives Attention},
  author = {M{\"u}ller, Sascha and Rothermund, Klaus and Wentura, Dirk},
  year = {2016},
  month = apr,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {69},
  number = {4},
  pages = {752--763},
  publisher = {{SAGE Publications}},
  issn = {1747-0218},
  doi = {10.1080/17470218.2015.1049624},
  abstract = {Attentional bias to gain- and loss-related stimuli was investigated in a dot-probe task. We used coloured stimuli that had acquired their valence during the experiment by signalling the chance to either win or lose points in a game task. Replicating previous findings with the additional singleton paradigm, we found attentional bias effects for both gain- and loss-related colours. The effects were due to delayed disengagement from valent stimuli, especially if they were positive, and could not be explained by nonattentional processes like behavioural freezing. Our findings suggest that stimuli signalling opportunities and dangers hold attention, supporting a general motivational relevance principle of the orienting of attention.},
  langid = {english},
  keywords = {Affective processing,Attentional orienting,Dot-probe,Relevance,Valence bias},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/E5N4DP2B/MÃ¼ller et al. - 2016 - Relevance drives attention Attentional bias for g.pdf}
}

@article{munnekeRewardCanModulate2015,
  title = {Reward Can Modulate Attentional Capture, Independent of Top-down Set},
  author = {Munneke, Jaap and Hoppenbrouwers, Sylco S. and Theeuwes, Jan},
  year = {2015},
  journal = {Attention, Perception \& Psychophysics},
  volume = {77},
  number = {8},
  pages = {2540--2548},
  issn = {1943-3921},
  doi = {10.3758/s13414-015-0958-6},
  abstract = {The traditional distinction between exogenous and endogenous attentional control has recently been enriched with an additional mode of control, termed ``selection history.'' Recent findings have indicated, for instance, that previously rewarded or punished stimuli capture more attention than their physical attributes would predict. As such, the value that is associated with certain stimuli modulates attentional capture. This particular influence has also been shown for endogenous attention. Although recent leads have emerged, elucidating the influences of reward on exogenous and endogenous attention, it remains unclear to what extent exogenous attention is modulated by reward when endogenous attention is already deployed. We used a Posner cueing task in which exogenous and endogenous cues were presented to guide attention. Crucially, the exogenous cue also indicated the reward value. That is, the color of the exogenous cue indicated how much reward could be obtained on a given trial. The results showed main effects of endogenous and exogenous attention (i.e., speeded reaction times when either cue was valid, as compared to when it was invalid). Crucially, an interaction between exogenous cue validity and reward level was observed, indicating that reward-based associative-learning processes rapidly influence attentional capture, even when endogenous attention has been actively deployed.},
  pmcid = {PMC4644218},
  pmid = {26178858},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/RRH7X9YY/Munneke et al. - 2015 - Reward can modulate attentional capture, independe.pdf}
}

@misc{navarroCombiningDimensionsFeatures2019,
  title = {Combining Dimensions and Features in Similarity-Based Representations},
  author = {Navarro, Danielle and Lee, Michael},
  year = {2019},
  month = aug,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/qejyb},
  abstract = {This paper develops a new representational model of similarity data that combines continuous dimensions with discrete features. An algorithm capable of learning these representations is described, and a Bayesian model selection approach for choosing the appropriate number of dimensions and features is developed. The approach is demonstrated on a classic data set that considers the similarities between the numbers 0 through 9.},
  keywords = {additive clustering,Bayesian statistics,Mathematical Psychology,multidimensional scaling,Quantitative Methods,similarity,Social and Behavioral Sciences},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/V45TUKQP/Navarro and Lee - 2019 - Combining dimensions and features in similarity-ba.pdf}
}

@article{navarroModelingIndividualDifferences2006,
  title = {Modeling Individual Differences Using {{Dirichlet}} Processes},
  author = {Navarro, Daniel J. and Griffiths, Thomas L. and Steyvers, Mark and Lee, Michael D.},
  year = {2006},
  month = apr,
  journal = {Journal of Mathematical Psychology},
  series = {Special {{Issue}} on {{Model Selection}}: {{Theoretical Developments}} and {{Applications}}},
  volume = {50},
  number = {2},
  pages = {101--122},
  issn = {0022-2496},
  doi = {10.1016/j.jmp.2005.11.006},
  abstract = {We introduce a Bayesian framework for modeling individual differences, in which subjects are assumed to belong to one of a potentially infinite number of groups. In this model, the groups observed in any particular data set are not viewed as a fixed set that fully explains the variation between individuals, but rather as representatives of a latent, arbitrarily rich structure. As more people are seen, and more details about the individual differences are revealed, the number of inferred groups is allowed to grow. We use the Dirichlet process\textemdash a distribution widely used in nonparametric Bayesian statistics\textemdash to define a prior for the model, allowing us to learn flexible parameter distributions without overfitting the data, or requiring the complex computations typically required for determining the dimensionality of a model. As an initial demonstration of the approach, we present three applications that analyze the individual differences in category learning, choice of publication outlets, and web-browsing behavior.},
  langid = {english},
  keywords = {Bayesian nonparametrics,Dirichlet processes,Individual differences},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/L7HNEE3G/Navarro et al. - 2006 - Modeling individual differences using Dirichlet pr.pdf}
}

@misc{OvertAttentionalCapture,
  title = {Overt Attentional Capture by Reward-Related Stimuli Overcomes Inhibitory Suppression.},
  howpublished = {https://psycnet-apa-org.ezproxy.library.uq.edu.au/fulltext/2020-19425-001.html}
}

@inproceedings{parvanehCounterfactualVisionandLanguageNavigation2020,
  title = {Counterfactual {{Vision-and-Language Navigation}}: {{Unravelling}} the {{Unseen}}},
  shorttitle = {Counterfactual {{Vision-and-Language Navigation}}},
  booktitle = {{{NeurIPS}}},
  author = {Parvaneh, Amin and Abbasnejad, Ehsan and Teney, Damien and Shi, Qinfeng and van den Hengel, Anton},
  year = {2020},
  month = jan,
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/73TPSN7Z/forum.html}
}

@book{pearlCausality2009,
  title = {Causality},
  author = {Pearl, J.},
  year = {2009},
  edition = {Second},
  publisher = {{Cambridge University Press}},
  address = {{Cambridge}},
  doi = {10.1017/CBO9780511803161},
  abstract = {Written by one of the preeminent researchers in the field, this book provides a comprehensive exposition of modern analysis of causation. It shows how causality has grown from a nebulous concept into a mathematical theory with significant applications in the fields of statistics, artificial intelligence, economics, philosophy, cognitive science, and the health and social sciences. Judea Pearl presents and unifies the probabilistic, manipulative, counterfactual, and structural approaches to causation and devises simple mathematical tools for studying the relationships between causal connections and statistical associations. Cited in more than 2,100 scientific publications, it continues to liberate scientists from the traditional molds of statistical thinking. In this revised edition, Judea Pearl elucidates thorny issues, answers readers' questions, and offers a panoramic view of recent advances in this field of research. Causality will be of interest to students and professionals in a wide variety of fields. Dr Judea Pearl has received the 2011 Rumelhart Prize for his leading research in Artificial Intelligence (AI) and systems from The Cognitive Science Society.},
  isbn = {978-0-521-89560-6},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/5LIAJF2E/B0046844FAE10CBF274D4ACBDAEB5F5B.html}
}

@article{pearlStructuralCounterfactualsBrief2013,
  title = {Structural {{Counterfactuals}}: {{A Brief Introduction}}},
  shorttitle = {Structural {{Counterfactuals}}},
  author = {Pearl, Judea},
  year = {2013},
  journal = {Cognitive Science},
  volume = {37},
  number = {6},
  pages = {977--985},
  issn = {1551-6709},
  doi = {10.1111/cogs.12065},
  abstract = {Recent advances in causal reasoning have given rise to a computational model that emulates the process by which humans generate, evaluate, and distinguish counterfactual sentences. Contrasted with the ``possible worlds'' account of counterfactuals, this ``structural'' model enjoys the advantages of representational economy, algorithmic simplicity, and conceptual clarity. This introduction traces the emergence of the structural model and gives a panoramic view of several applications where counterfactual reasoning has benefited problem areas in the empirical sciences.},
  langid = {english},
  keywords = {Causal reasoning,Counterfactuals,Structural models},
  annotation = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1111/cogs.12065},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/3XR46QDM/Pearl - 2013 - Structural Counterfactuals A Brief Introduction.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/CPD9BY7V/cogs.html}
}

@article{pearsonOvertAttentionalCapture2020,
  title = {Overt Attentional Capture by Reward-Related Stimuli Overcomes Inhibitory Suppression},
  author = {Pearson, Daniel and Watson, Poppy and Cheng, Phillip (Xin) and Le Pelley, Mike E.},
  year = {2020},
  journal = {Journal of Experimental Psychology: Human Perception and Performance},
  volume = {46},
  number = {5},
  pages = {489--501},
  publisher = {{American Psychological Association}},
  address = {{US}},
  issn = {1939-1277},
  doi = {10.1037/xhp0000728},
  abstract = {Salient-but-irrelevant distractors can automatically capture attention and eye-gaze in visual search. However, recent findings have suggested that attention to salient-but-irrelevant stimuli can be suppressed when observers use a specific target template to guide their search (i.e., feature search). A separate line of research has indicated that attentional selection is influenced by factors other than the physical salience of a stimulus and the observer's goals. For instance, pairing a stimulus with reward has been shown to increase the extent to which it captures attention and gaze (as though it has become more physically salient), even when such capture has negative consequences for the observer. Here we used eye-tracking with a rewarded visual search task to investigate whether capture by reward can be suppressed in the same way as capture by physical salience. When participants were encouraged to use feature search, attention to a distractor paired with relatively small reward was suppressed. However, under the same conditions attention was captured by a distractor paired with large reward, even when such capture resulted in reward omission. These findings suggest that reward-related stimuli are given special priority within the visual attention system over and above physically salient stimuli, and have implications for our understanding of real-world biases to reward-related stimuli, such as those seen in addiction. (PsycInfo Database Record (c) 2021 APA, all rights reserved)},
  keywords = {Attentional Capture,Eye Fixation,Rewards,Selective Attention,Stimulus Salience,Visual Attention,Visual Search,Visual Tracking},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/UULDHJAQ/Pearson et al. - 2020 - Overt attentional capture by reward-related stimul.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/G6ZMRSGP/2020-19425-001.html}
}

@article{pelliVideoToolboxSoftwareVisual1997,
  ids = {pelliVideoToolboxSoftwareVisual1997a},
  title = {The {{VideoToolbox}} Software for Visual Psychophysics: Transforming Numbers into Movies},
  shorttitle = {The {{VideoToolbox}} Software for Visual Psychophysics},
  author = {Pelli, D.G.},
  year = {1997},
  month = jan,
  journal = {Spatial Vision},
  volume = {10},
  number = {4},
  pages = {437--442},
  publisher = {{Brill}},
  issn = {1568-5683},
  doi = {10.1163/156856897X00366},
  abstract = {The VideoToolbox is a free collection of two hundred C subroutines for Macintosh computers that calibrates and controls the computer-display interface to create accurately specified visual stimuli. High-level platform-independent languages like MATLAB are best for creating the numbers that describe the desired images. Low-level, computer-specific VideoToolbox routines control the hardware that transforms those numbers into a movie. Transcending the particular computer and language, we discuss the nature of the computer-display interface, and how to calibrate and control it.},
  chapter = {Spatial Vision},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/B2NHKQGS/Pelli - 1997 - The VideoToolbox software for visual psychophysics.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/G6MFTHKC/Pelli - 1997 - The VideoToolbox software for visual psychophysics.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/D7SMSH5H/article-p437_16.html;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/UCIFZ8Q4/156856897x00366.html}
}

@article{pischeddaEffectCounterfactualInformation2020,
  title = {The {{Effect}} of {{Counterfactual Information}} on {{Outcome Value Coding}} in {{Medial Prefrontal}} and {{Cingulate Cortex}}: {{From}} an {{Absolute}} to a {{Relative Neural Code}}},
  shorttitle = {The {{Effect}} of {{Counterfactual Information}} on {{Outcome Value Coding}} in {{Medial Prefrontal}} and {{Cingulate Cortex}}},
  author = {Pischedda, D. and Palminteri, S. and Coricelli, G.},
  year = {2020},
  month = apr,
  journal = {Journal of Neuroscience},
  volume = {40},
  number = {16},
  pages = {3268--3277},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1712-19.2020},
  abstract = {Adaptive coding of stimuli is well documented in perception, where it supports efficient encoding over a broad range of possible percepts. Recently, a similar neural mechanism has been reported also in value-based decision, where it allows optimal encoding of vast ranges of values in PFC: neuronal response to value depends on the choice context (relative coding), rather than being invariant across contexts (absolute coding). Additionally, value learning is sensitive to the amount of feedback information: providing complete feedback (both obtained and forgone outcomes) instead of partial feedback (only obtained outcome) improves learning. However, it is unclear whether relative coding occurs in all PFC regions and how it is affected by feedback information. We systematically investigated univariate and multivariate feedback encoding in various mPFC regions and compared three modes of neural coding: absolute, partially-adaptive and fully-adaptive. Twenty-eight human participants (both sexes) performed a learning task while undergoing fMRI scanning. On each trial, they chose between two symbols associated with a certain outcome. Then, the decision outcome was revealed. Notably, in one-half of the trials participants received partial feedback, whereas in the other half they got complete feedback. We used univariate and multivariate analysis to explore value encoding in different feedback conditions. We found that both obtained and forgone outcomes were encoded in mPFC, but with opposite sign in its ventral and dorsal subdivisions. Moreover, we showed that increasing feedback information induced a switch from absolute to relative coding. Our results suggest that complete feedback information enhances context-dependent outcome encoding. SIGNIFICANCE STATEMENT This study offers a systematic investigation of the effect of the amount of feedback information (partial vs complete) on univariate and multivariate outcome value encoding, within multiple regions in mPFC and cingulate cortex that are critical for value-based decisions and behavioral adaptation. Moreover, we provide the first comparison of three possible models of neural coding (i.e., absolute, partially-adaptive, and fully-adaptive coding) of value signal in these regions, by using commensurable measures of prediction accuracy. Taken together, our results help build a more comprehensive picture of how the human brain encodes and processes outcome value. In particular, our results suggest that simultaneous presentation of obtained and foregone outcomes promotes relative value representation.},
  chapter = {Research Articles},
  copyright = {Copyright \textcopyright{} 2020 the authors},
  langid = {english},
  pmid = {32156831},
  keywords = {counterfactual,decision-making,multivariate encoding,reinforcement learning,relative coding,reward encoding},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/TMAI8TIS/Pischedda et al. - 2020 - The Effect of Counterfactual Information on Outcom.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/ZU2IA6YQ/3268.html}
}

@article{posnerOrientingAttention1980a,
  title = {Orienting of {{Attention}}},
  author = {Posner, M.I.},
  year = {1980},
  month = feb,
  journal = {Quarterly Journal of Experimental Psychology},
  volume = {32},
  number = {1},
  pages = {3--25},
  publisher = {{SAGE Publications}},
  issn = {0033-555X},
  doi = {10.1080/00335558008248231},
  abstract = {Bartlett viewed thinking as a high level skill exhibiting ballistic properties that he called its ``point of no return''. This paper explores one aspect of cognition through the use of a simple model task in which human subjects are asked to commit attention to a position in visual space other than fixation. This instruction is executed by orienting a covert (attentional) mechanism that seems sufficiently time locked to external events that its trajectory can be traced across the visual field in terms of momentary changes in the efficiency of detecting stimuli. A comparison of results obtained with alert monkeys, brain injured and normal human subjects shows the relationship of this covert system to saccadic eye movements and to various brain systems controlling perception and motion. In accordance with Bartlett's insight, the possibility is explored that similar principles apply to orienting of attention toward sensory input and orienting to the semantic structures used in thinking.},
  langid = {english}
}

@article{prinzmetalSpatialAttentionEnvironmental2015,
  title = {Spatial Attention and Environmental Information},
  author = {Prinzmetal, W. and Whiteford, K.L. and Austerweil, J.L. and Landau, A.},
  year = {2015},
  month = oct,
  journal = {Journal of Experimental Psychology. Human Perception and Performance},
  volume = {41},
  number = {5},
  pages = {1396--1408},
  issn = {1939-1277},
  doi = {10.1037/a0039429},
  abstract = {Navigating through our perceptual environment requires constant selection of behaviorally relevant information and irrelevant information. Spatial cues guide attention to information in the environment that is relevant to the current task. How does the amount of information provided by a location cue and irrelevant information influence the deployment of attention and what are the processes underlying this effect? To address these questions, we used a spatial cueing paradigm to measure the relationship between cue predictability (measured in bits of information) and the voluntary attention effect, the benefit in reaction time (RT) because of cueing a target. We found a linear relationship between cue predictability and the attention effect. To analyze the cognitive processes producing this effect, we used a simple RT model, the Linear Ballistic Accumulator model. We found that informative cues reduced the amount of evidence necessary to make a response (the threshold), regardless of the presence of irrelevant information (i.e., distractors). However, a change in the rate of evidence accumulation occurred when distractors were present in the display. Thus, the mechanisms underlying the deployment of attention are exquisitely tuned to the amount and behavioral relevancy of statistical information in the environment. (PsycINFO Database Record},
  langid = {english},
  pmid = {26168145},
  keywords = {Adult,Attention,Cues,Environment,Humans,Models; Psychological,Psychomotor Performance,Reaction Time,Space Perception,Young Adult}
}

@article{raoCounterfactualAttentionLearning2021,
  title = {Counterfactual {{Attention Learning}} for {{Fine-Grained Visual Categorization}} and {{Re-identification}}},
  author = {Rao, Yongming and Chen, Guangyi and Lu, Jiwen and Zhou, Jie},
  year = {2021},
  month = aug,
  journal = {arXiv:2108.08728 [cs]},
  eprint = {2108.08728},
  eprinttype = {arxiv},
  primaryclass = {cs},
  abstract = {Attention mechanism has demonstrated great potential in fine-grained visual recognition tasks. In this paper, we present a counterfactual attention learning method to learn more effective attention based on causal inference. Unlike most existing methods that learn visual attention based on conventional likelihood, we propose to learn the attention with counterfactual causality, which provides a tool to measure the attention quality and a powerful supervisory signal to guide the learning process. Specifically, we analyze the effect of the learned visual attention on network prediction through counterfactual intervention and maximize the effect to encourage the network to learn more useful attention for fine-grained image recognition. Empirically, we evaluate our method on a wide range of fine-grained recognition tasks where attention plays a crucial role, including fine-grained image categorization, person re-identification, and vehicle re-identification. The consistent improvement on all benchmarks demonstrates the effectiveness of our method. Code is available at https://github.com/raoyongming/CAL},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning}
}

@incollection{raymondInteractionsAttentionEmotion2009,
  title = {Interactions of Attention, Emotion and Motivation},
  booktitle = {Progress in {{Brain Research}}},
  author = {Raymond, J.},
  editor = {Srinivasan, Narayanan},
  year = {2009},
  month = jan,
  series = {Attention},
  volume = {176},
  pages = {293--308},
  publisher = {{Elsevier}},
  doi = {10.1016/S0079-6123(09)17617-3},
  abstract = {Although successful visually guided action begins with sensory processes and ends with motor control, the intervening processes related to the appropriate selection of information for processing are especially critical because of the brain's limited capacity to handle information. Three important mechanisms \textemdash{} attention, emotion and motivation \textemdash{} contribute to the prioritization and selection of information. In this chapter, the interplay between these systems is discussed with emphasis placed on interactions between attention (or immediate task relevance of stimuli) and emotion (or affective evaluation of stimuli), and between attention and motivation (or the predicted value of stimuli). Although numerous studies have shown that emotional stimuli modulate mechanisms of selective attention in humans, little work has been directed at exploring whether such interactions can be reciprocal, that is, whether attention can influence emotional response. Recent work on this question (showing that distracting information is typically devalued upon later encounters) is reviewed in the first half of the chapter. In the second half, some recent experiments exploring how prior value-prediction learning (i.e., learning to associate potential outcomes, good or bad, with specific stimuli) plays a role in visual selection and conscious perception. The results indicate that some aspects of motivation act on selection independently of traditionally defined attention and other aspects interact with it.},
  langid = {english},
  keywords = {affective evaluation,attention,attentional blink,distractor devaluation,emotion,faces,motivation}
}

@article{raymondSelectiveVisualAttention2009a,
  title = {Selective {{Visual Attention}} and {{Motivation}}: {{The Consequences}} of {{Value Learning}} in an {{Attentional Blink Task}}},
  shorttitle = {Selective {{Visual Attention}} and {{Motivation}}},
  author = {Raymond, J. E. and O'Brien, J. L.},
  year = {2009},
  month = aug,
  journal = {Psychological Science},
  volume = {20},
  number = {8},
  pages = {981--988},
  publisher = {{SAGE Publications Inc}},
  issn = {0956-7976},
  doi = {10.1111/j.1467-9280.2009.02391.x},
  abstract = {Learning to associate the probability and value of behavioral outcomes with specific stimuli (value learning) is essential for rational decision making. However, in demanding cognitive conditions, access to learned values might be constrained by limited attentional capacity. We measured recognition of briefly presented faces seen previously in a value-learning task involving monetary wins and losses; the recognition task was performed both with and without constraints on available attention. Regardless of available attention, recognition was substantially enhanced for motivationally salient stimuli (i.e., stimuli highly predictive of outcomes), compared with equally familiar stimuli that had weak or no motivational salience, and this effect was found regardless of valence (win or loss). However, when attention was constrained (because stimuli were presented during an attentional blink, AB), valence determined recognition; win-associated faces showed no AB, but all other faces showed large ABs. Motivational salience acts independently of attention to modulate simple perceptual decisions, but when attention is limited, visual processing is biased in favor of reward-associated stimuli.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/RAS487ED/Raymond and O'Brien - 2009 - Selective Visual Attention and Motivation The Con.pdf}
}

@article{risticNewFormHuman2012,
  title = {A New Form of Human Spatial Attention: {{Automated}} Symbolic Orienting},
  shorttitle = {A New Form of Human Spatial Attention},
  author = {Ristic, J. and Kingstone, A.},
  year = {2012},
  month = mar,
  journal = {Visual Cognition},
  volume = {20},
  number = {3},
  pages = {244--264},
  publisher = {{Routledge}},
  issn = {1350-6285},
  doi = {10.1080/13506285.2012.658101},
  abstract = {The control of human attention is typically conceptualized either in terms of exogenous automatic processes that are driven by external sensory stimulation or endogenous strategic processes that are driven by internal expectancies about events in the environment. However, this classic dichotomy has struggled to explain a wealth of new data demonstrating that behaviourally and biologically relevant visual stimuli, like arrow and eye direction, elicit shifts of spatial attention that on the one hand, appear exogenous, and on the other hand, endogenous. To address this issue, we used a double-cueing task that combined arrows with classic cues known to invoke either exogenous or endogenous orienting. Our data suggest that behaviourally relevant directional cues, like arrows, engage a new form of cortically mediated orienting\textemdash automated symbolic orienting\textemdash that operates independent of, and in parallel with, the two classic forms of exogenous and endogenous spatial attention.},
  keywords = {Behaviourally relevant cues,Human attention,Spatial orienting},
  annotation = {\_eprint: https://doi.org/10.1080/13506285.2012.658101},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/2UILVUJZ/Ristic and Kingstone - 2012 - A new form of human spatial attention Automated s.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/ZVSE5LKI/13506285.2012.html}
}

@article{roelfsemaImplementationVisualRoutines2000,
  title = {The Implementation of Visual Routines},
  author = {Roelfsema, Pieter R and Lamme, Victor A. F and Spekreijse, Henk},
  year = {2000},
  month = jun,
  journal = {Vision Research},
  volume = {40},
  number = {10},
  pages = {1385--1411},
  issn = {0042-6989},
  doi = {10.1016/S0042-6989(00)00004-3},
  abstract = {Many visual tasks can be decomposed into a sequence of simpler subtasks. Ullman suggested that such subtasks are carried out by elemental operations that are implemented by specialized processes in the visual brain [Ullman, S. (1984). Visual routines. Cognition (18), 97\textendash 159]. According to this hypothesis, there are a limited number of elemental operations that, since they can be applied sequentially, may nevertheless give rise to a large number of visual routines. Examples of such elemental operations are visual search, texture segregation and contour grouping. Here we attempt to delineate how such elemental operations are implemented in the visual brain. When an image appears, feedforward processing rapidly leads to an activity pattern that is distributed across many visual areas. Thereafter, elemental operations come into play, and these are implemented by the modulation of firing rates. Firing rate modulations effectuate grouping of neural responses into coherent object representations. Moreover, they permit transfer of information from one operator to the next, which allows flexibility in the sequencing of operations. We discuss how the elemental operations provide a tool to relate cortical physiology to psychophysics, and suggest a reclassification of pre-attentive and attentive processes.},
  langid = {english},
  keywords = {Binding,Contour integration,Curve tracing,Elemental operations,Firing rate modulations,Object-based attention,Perceptual organization,Texture segregation,Visual routines,Visual search},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/XDQ4JU3K/S0042698900000043.html}
}

@article{rouderAreThereReliable2021,
  title = {Are {{There Reliable Qualitative Individual Differences}} in {{Cognition}}?},
  author = {Rouder, Jeffrey and Haaf, Julia M.},
  year = {2021},
  month = aug,
  journal = {Journal of Cognition},
  volume = {4},
  number = {1},
  pages = {46},
  publisher = {{Ubiquity Press}},
  issn = {2514-4820},
  doi = {10.5334/joc.131},
  abstract = {In this paper we propose a new set of questions that focus on the direction of effects. In almost all studies the direction is important. For example, in a Stroop task we expect responses to incongruent items to be slower than those to congruent ones, and this direction implies one theoretical explanation. Yet, if congruent words are slowed down relative to incongruent words we would have a completely different theoretical explanation. We ask a `does everybody' question, such as, `does every individual show a Stroop effect in the same direction?' Or, `does every individual respond faster to loud tones than soft tones?' If all individuals truly have effects in the same direction that implicate a common theory, we term the differences among them as quantitative individual differences. Conversely, if all individuals truly have effects in different directions that implicate different theories, we term the differences among them as qualitative individual differences. Here, we provide a users guide to the question of whether individual differences are qualitative or quantitative. We discuss theoretical issues, methodological advances, new software for assessment, and, most importantly, how the question impacts theory development in cognitive science. Our hope is that this mode of analysis is a productive tool in researchers' toolkits.},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  langid = {english},
  keywords = {Bayesian Inference,Cognitive Tasks,Hierarchical Models,Individual Differences},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/EN6RMH5H/Rouder and Haaf - 2021 - Are There Reliable Qualitative Individual Differen.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/YRYBUN2X/joc.131.html}
}

@article{sawakiHowAttentionChanges2015,
  title = {How Attention Changes in Response to Incentives},
  author = {Sawaki, Risa and Luck, Steven J. and Raymond, Jane E.},
  year = {2015},
  month = nov,
  journal = {Journal of cognitive neuroscience},
  volume = {27},
  number = {11},
  pages = {2229--2239},
  issn = {0898-929X},
  doi = {10.1162/jocn_a_00847},
  abstract = {Although the performance of simple cognitive tasks can be enhanced if an incentive is provided, the mechanisms enabling such motivational control are not known. The present study sought to uncover how mechanisms of attention and readiness are altered by reward-associated incentive stimuli. We measured EEG/ERP activity as human adults viewed a high- or low-incentive cue, experienced a short preparation interval, and then performed a simple visual search task to gain the predicted reward. Search performance was faster with high versus low incentives, and this was accompanied by distinct incentive-related EEG/ERP patterns at each phase of the task (incentive, preparation, and search). First, and most surprisingly, attention to high but not low incentive cues was actively suppressed, as indexed by a PD component in response to the incentive display. During the subsequent preparation interval, neural oscillations in the alpha frequency range were reduced following high-incentive cues, indicating heightened visual readiness. Finally, attentional orienting to the target in the search array was deployed with relatively little effort on high-incentive trials, as indexed by a reduced N2pc component. These results reveal the chain of events by which the brain's executive control mechanisms respond to incentives by altering the operation of multiple processing systems to produce optimal performance.},
  pmcid = {PMC4589447},
  pmid = {26151604},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/AX2II8S3/Sawaki et al. - 2015 - How attention changes in response to incentives.pdf}
}

@article{schmitzNormalizationCholinergicMicrocircuit2018a,
  title = {Normalization and the {{Cholinergic Microcircuit}}: {{A Unified Basis}} for {{Attention}}},
  shorttitle = {Normalization and the {{Cholinergic Microcircuit}}},
  author = {Schmitz, Taylor W. and Duncan, John},
  year = {2018},
  month = may,
  journal = {Trends in Cognitive Sciences},
  volume = {22},
  number = {5},
  pages = {422--437},
  issn = {1879-307X},
  doi = {10.1016/j.tics.2018.02.011},
  abstract = {Attention alters three key properties of population neural activity - firing rate, rate variability, and shared variability between neurons. All three properties are well explained by a single canonical computation - normalization - that acts across hierarchically integrated brain systems. Combining data from rodents and nonhuman primates, we argue that cortical cholinergic modulation originating from the basal forebrain closely mimics the effects of directed attention on these three properties of population neural activity. Cholinergic modulation of the cortical microcircuit underlying normalization may represent a key biological basis for the rapid and flexible changes in population neuronal coding that are required by directed attention.},
  langid = {english},
  pmid = {29576464},
  keywords = {Acetylcholine,acetylcholine/cholinergic,Animals,attention,Attention,basal forebrain,Cerebral Cortex,cortical circuit,divisive normalization,Neural Pathways,noise correlation}
}

@article{sigalaHierarchicalCodingSequential2008,
  title = {Hierarchical Coding for Sequential Task Events in the Monkey Prefrontal Cortex},
  author = {Sigala, Natasha and Kusunoki, Makoto and {Nimmo-Smith}, Ian and Gaffan, David and Duncan, John},
  year = {2008},
  month = aug,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {105},
  number = {33},
  pages = {11969--11974},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.0802569105},
  abstract = {The frontal lobes play a key role in sequential organization of behavior. Little is known, however, of the way frontal neurons code successive phases of a structured task plan. Using correlational analysis, we asked how a population of frontal cells represents the multiple events of a complex sequential task. Monkeys performed a conventional cue\textendash target association task, with distinct cue, delay, and target phases. Across the population of recorded cells, we examined patterns of activity for different task phases, and in the same phase, for different stimulus objects. The results show hierarchical representation of task events. For different task phases, there were different, approximately orthogonal patterns of activity across the population of neurons. Modulations of each basic pattern encoded stimulus information within each phase. By orthogonal coding, the frontal lobe may control transitions between the discrete steps of a mental program; by correlated coding within each step, similar operations may be applied to different stimulus content.},
  chapter = {Biological Sciences},
  copyright = {\textcopyright{} 2008 by The National Academy of Sciences of the USA.  Freely available online through the PNAS open access option.},
  langid = {english},
  pmid = {18689686},
  keywords = {correlated coding,orthogonal coding,pair associative task,sequence representation},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/ZCHVSEXP/Sigala et al. - 2008 - Hierarchical coding for sequential task events in .pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/39S4PRQJ/11969.html}
}

@article{stanisorUnifiedSelectionSignal2013a,
  title = {A Unified Selection Signal for Attention and Reward in Primary Visual Cortex},
  author = {St{\u a}ni{\c s}or, L. and Togt, C. and Pennartz, C.M.A. and Roelfsema, P.R.},
  year = {2013},
  month = may,
  journal = {Proceedings of the National Academy of Sciences},
  volume = {110},
  number = {22},
  pages = {9136--9141},
  publisher = {{National Academy of Sciences}},
  issn = {0027-8424, 1091-6490},
  doi = {10.1073/pnas.1300117110},
  abstract = {Stimuli associated with high rewards evoke stronger neuronal activity than stimuli associated with lower rewards in many brain regions. It is not well understood how these reward effects influence activity in sensory cortices that represent low-level stimulus features. Here, we investigated the effects of reward information in the primary visual cortex (area V1) of monkeys. We found that the reward value of a stimulus relative to the value of other stimuli is a good predictor of V1 activity. Relative value biases the competition between stimuli, just as has been shown for selective attention. The neuronal latency of this reward value effect in V1 was similar to the latency of attentional influences. Moreover, V1 neurons with a strong value effect also exhibited a strong attention effect, which implies that relative value and top\textendash down attention engage overlapping, if not identical, neuronal selection mechanisms. Our findings demonstrate that the effects of reward value reach down to the earliest sensory processing levels of the cerebral cortex and imply that theories about the effects of reward coding and top\textendash down attention on visual representations should be unified.},
  chapter = {Biological Sciences},
  copyright = {\textcopyright{}  . Freely available online through the PNAS open access option.},
  langid = {english},
  pmid = {23676276},
  keywords = {object-based attention,reward expectancy},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/A2TMSGGF/StÄƒniÅŸor et al. - 2013 - A unified selection signal for attention and rewar.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/KVK883E9/9136.html}
}

@article{stankevichRewardAssociationsSpatial2014,
  title = {Reward Associations and Spatial Probabilities Produce Additive Effects on Attentional Selection},
  author = {Stankevich, B.A. and Geng, J.J.},
  year = {2014},
  month = nov,
  journal = {Attention, Perception, \& Psychophysics},
  volume = {76},
  number = {8},
  pages = {2315--2325},
  issn = {1943-393X},
  doi = {10.3758/s13414-014-0720-5},
  abstract = {Recent studies have shown that reward history acts as a powerful attentional bias, even overcoming top-down goals. This has led to the suggestion that rewards belong to a class of attentional cues based on selection history, which are defined by past outcomes with a stimulus feature. Selection history is thought to be separate from traditional attentional cues based on physical salience and voluntary goals, but there is relatively little understanding of how selection history operates as a mechanism of attentional selection. Critically, it has yet to be understood how multiple sources of selection history interact when presented simultaneously. For example, it may be easier to find something we like if it also appears in a predictable location. We therefore pitted spatial probabilities against reward associations and found that the two sources of information had independent and additive effects. Additionally, the strength of the two sources in biasing attentional selection could be equated. In contrast, while a nonpredictive but perceptually salient cue also exhibited independent and additive effects with reward, reward associations dominated the perceptually salient cue at all levels. Our data indicate that reward associations are part of a class of particularly potent attentional cues that guide behavior through learned expectations. However, selection history should not be thought of as a unitary concept but should be understood as a collection of independent sources of information that bias attention in a similar fashion.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/G7K6DMHH/Stankevich and Geng - 2014 - Reward associations and spatial probabilities prod.pdf}
}

@article{staudiglSaccadesArePhaselocked2017,
  title = {Saccades Are Phase-Locked to Alpha Oscillations in the Occipital and Medial Temporal Lobe during Successful Memory Encoding},
  author = {Staudigl, Tobias and Hartl, Elisabeth and Noachtar, Soheyl and Doeller, Christian F. and Jensen, Ole},
  year = {2017},
  month = dec,
  journal = {PLOS Biology},
  volume = {15},
  number = {12},
  pages = {e2003404},
  publisher = {{Public Library of Science}},
  issn = {1545-7885},
  doi = {10.1371/journal.pbio.2003404},
  abstract = {Efficient sampling of visual information requires a coordination of eye movements and ongoing brain oscillations. Using intracranial and magnetoencephalography (MEG) recordings, we show that saccades are locked to the phase of visual alpha oscillations and that this coordination is related to successful mnemonic encoding of visual scenes. Furthermore, parahippocampal and retrosplenial cortex involvement in this coordination reflects effective vision-to-memory mapping, highlighting the importance of neural oscillations for the interaction between visual and memory domains.},
  langid = {english},
  keywords = {Attention,Eye movements,Magnetoencephalography,Memory,Permutation,Test statistics,Three-phase planar bone scintigraphy,Vision},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/BXV3AL9P/Staudigl et al. - 2017 - Saccades are phase-locked to alpha oscillations in.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/6B8WR5DA/article.html}
}

@article{sternbergDiscoveryProcessingStages1969,
  title = {The Discovery of Processing Stages: {{Extensions}} of {{Donders}}' Method},
  shorttitle = {The Discovery of Processing Stages},
  author = {Sternberg, S.},
  year = {1969},
  month = jan,
  journal = {Acta Psychologica},
  volume = {30},
  pages = {276--315},
  issn = {0001-6918},
  doi = {10.1016/0001-6918(69)90055-9},
  abstract = {A new method is proposed for using reaction-time (RT) measurements to study stages of information processing. It overcomes limitations of Donders' and more recent methods, and permits the discovery of stages, assessment of their properties, and separate testing of the additivity and stochastic independence of stage durations. The main feature of the additive-factor method is the search for non-interacting effects of experimental factors on mean RT. The method is applied to several binary-classification experiments, where it leads to a four-stage model, and to an identification experiment, where it distinguishes two stages. The sets of stages inferred from both these and other data are shown to carry substantive implications. It is demonstrated that stage-durations may be additive without being stochastically independent, a result that is relevant to the formulation of mathematical models of RT.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/XE2DD2LH/0001691869900559.html}
}

@misc{StructuralPrimingSupported,
  title = {Structural Priming Is Supported by Different Components of Nondeclarative Memory: {{Evidence}} from Priming across the Lifespan.},
  howpublished = {https://psycnet-apa-org.ezproxy.library.uq.edu.au/fulltext/2020-82396-001.html}
}

@incollection{tsotsosAttentionCognitionPrinciples2017,
  title = {Attention and {{Cognition}}: {{Principles}} to {{Guide Modeling}}},
  shorttitle = {Attention and {{Cognition}}},
  booktitle = {Computational and {{Cognitive Neuroscience}} of {{Vision}}},
  author = {Tsotsos, J.K.},
  editor = {Zhao, Q.},
  year = {2017},
  series = {Cognitive {{Science}} and {{Technology}}},
  pages = {277--295},
  publisher = {{Springer}},
  address = {{Singapore}},
  doi = {10.1007/978-981-10-0213-7_12},
  abstract = {Interest in the modeling of visual attention and cognition is strong with the number of models growing quickly. It thus becomes important to try to consolidate what all this activity has demonstrated in terms of what principles may be abstracted from the collective experience that can guide future research. This is not a straightforward task; many have tried and have little to show for it. Here, a different view is presented, one that attempts to combine multiple perspectives on the problem. The novelty is that in contrast with the vast majority of past work, there is an explicit assertion that no single principle can capture the complexities of human attentional and cognitive behavior. There are several principles, each defined in a particular context, with interactions among them. Many previous authors have stated principles that in fact are more correctly considered as modeling philosophies or requirements and these will be so distinguished. The development of a model of human visual cognition is dependent on the choice of which experimental observations act as constraints during its development (Tsotsos 2014). Those constraints provide a means to select solutions among those potential ones that satisfy the principles. Here, we begin by proposing a set of elements that may be considered as the components of attention, without any claims or completeness or optimality, and these will act as the first level set of constraints on any modeling activity. A look at specific models of attention and cognitive architectures will reveal a variety of principles, philosophies and requirements that have been shown to be important. This will be followed by the introduction of the Survival Requirement as a replacement for any over-arching principle of optimality because there still is a need for a selection criterion for choosing among competing solutions. The presentation will conclude by considering how progress on open problems in neuroscience may be facilitated by considering this list of principles, philosophies and requirements.},
  isbn = {978-981-10-0213-7},
  langid = {english},
  keywords = {Attention Executive,Cognitive Architecture,Modeling Principle,Restrict Boltzmann Machine,Visual Attention},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/JDK57P54/Tsotsos - 2017 - Attention and Cognition Principles to Guide Model.pdf}
}

@article{tsotsosControlAttentionalProcesses2021,
  ids = {tsotsosControlAttentionalProcesses2021a},
  title = {On the {{Control}} of {{Attentional Processes}} in {{Vision}}},
  author = {Tsotsos, J.K. and Abid, O. and Kotseruba, J. and Solbach, M.D.},
  year = {2021},
  month = jan,
  journal = {arXiv:2101.01533 [cs, q-bio]},
  eprint = {2101.01533},
  eprinttype = {arxiv},
  primaryclass = {cs, q-bio},
  abstract = {The study of attentional processing in vision has a long and deep history. Recently, several papers have presented insightful perspectives into how the coordination of multiple attentional functions in the brain might occur. These begin with experimental observations and the authors propose structures, processes, and computations that might explain those observations. Here, we consider a perspective that past works have not, as a complementary approach to the experimentally-grounded ones. We approach the same problem as past authors but from the other end of the computational spectrum, from the problem nature, as Marr's Computational Level would prescribe. What problem must the brain solve when orchestrating attentional processes in order to successfully complete one of the myriad possible visuospatial tasks at which we as humans excel? The hope, of course, is for the approaches to eventually meet and thus form a complete theory, but this is likely not soon. We make the first steps towards this by addressing the necessity of attentional control, examining the breadth and computational difficulty of the visuospatial and attentional tasks seen in human behavior, and suggesting a sketch of how attentional control might arise in the brain. The key conclusions of this paper are that an executive controller is necessary for human attentional function in vision, and that there is a 'first principles' computational approach to its understanding that is complementary to the previous approaches that focus on modelling or learning from experimental observations directly.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computational Complexity,Computer Science - Computer Vision and Pattern Recognition,Computer Science - Machine Learning,Quantitative Biology - Neurons and Cognition},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/LY6XWYZ8/Tsotsos et al. - 2021 - On the Control of Attentional Processes in Vision.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/QHUJWQEM/Tsotsos et al. - 2021 - On the Control of Attentional Processes in Vision.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/5IHVG5HF/2101.html;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/EXX3UFBS/2101.html}
}

@article{tsotsosControlAttentionalProcesses2021a,
  title = {On the Control of Attentional Processes in Vision},
  author = {Tsotsos, J.K. and Abid, O. and Kotseruba, J. and Solbach, M.D.},
  year = {2021},
  month = apr,
  journal = {Cortex},
  volume = {137},
  pages = {305--329},
  issn = {0010-9452},
  doi = {10.1016/j.cortex.2021.01.001},
  abstract = {The study of attentional processing in vision has a long and deep history. Recently, several papers have presented insightful perspectives into how the coordination of multiple attentional functions in the brain might occur. These begin with experimental observations and the authors propose structures, processes, and computations that might explain those observations. Here, we consider a perspective that past works have not, as a complementary approach to the experimentally-grounded ones. We approach the same problem as past authors but from the other end of the computational spectrum, from the problem nature, as Marr's Computational Level would prescribe. What problem must the brain solve when orchestrating attentional processes in order to successfully complete one of the myriad possible visuospatial tasks at which we as humans excel? The hope, of course, is for the approaches to eventually meet and thus form a complete theory, but this is likely not soon. We make the first steps towards this by addressing the necessity of attentional control, examining the breadth and computational difficulty of the visuospatial and attentional tasks seen in human behavior, and suggesting a sketch of how attentional control might arise in the brain. The key conclusions of this paper are that an executive controller is necessary for human attentional function in vision, and that there is a 'first principles' computational approach to its understanding that is complementary to the previous approaches that focus on modelling or learning from experimental observations directly.},
  langid = {english},
  keywords = {Attention,Cognitive program,Control,Selective tuning,Vision},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/B5Y2PASF/Tsotsos et al. - 2021 - On the control of attentional processes in vision.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/UBDSUIU2/S0010945221000150.html}
}

@incollection{ullmanVisualRoutinesThis1987,
  title = {Visual routines**{{This}} Report Describes Research Done at the {{Artificial Intelligence Laboratory}} of the {{Massachusetts Institute}} of {{Technology}}. {{Support}} for the Laboratory's Artificial Intelligence Research Is Provided in Part by the {{Advanced Research Projects Agency}} of the {{Department}} of {{Defense}} under {{Office}} of {{Naval Research}} Contract {{N00014}}\textendash 80-{{C-0505}} and in Part by {{National Science Foundation Grant}} 79\textendash{{23110MCS}}. {{Reprint}} Requests Should Be Sent to {{Shimon Ullman Department}} of {{Psychology}} and {{Artificial Intelligence Laboratory}}, {{M}}.{{I}}.{{T}}., {{Cambridge}}, {{MA}} 02139, {{U}}.{{S}}.{{A}}.},
  booktitle = {Readings in {{Computer Vision}}},
  author = {Ullman, SHIMON},
  editor = {Fischler, Martin A. and Firschein, Oscar},
  year = {1987},
  month = jan,
  pages = {298--328},
  publisher = {{Morgan Kaufmann}},
  address = {{San Francisco (CA)}},
  doi = {10.1016/B978-0-08-051581-6.50035-0},
  abstract = {This paper examines the processing of visual information beyond the creation of the early representations. A fundamental requirement at this level is the capacity to establish visually abstract shape properties and spatial relations. This capacity plays a major role in object recognition, visually guided manipulation, and more abstract visual thinking. For the human visual system, the perception of spatial properties and relations that are complex from a computational standpoint nevertheless often appears deceivingly immediate and effortless. The proficiency of the human system in analyzing spatial information far surpasses the capacities of current artificial systems. The study of the computations that underlie this competence may therefore lead to the development of new more efficient methods for the spatial analysis of visual information. The perception of abstract shape properties and spatial relations raises fundamental difficulties with major implications for the overall processing of visual information. It will be argued that the computation of spatial relations divides the analysis of visual information into two main stages. The first is the bottom-up creation of certain representations of the visible environment. The second stage involves the application of processes called `visual routines' to the representations constructed in the first stage. These routines can establish properties and relations that cannot be represented explicitly in the initial representations. Visual routines are composed of sequences of elemental operations. Routines for different properties and relations share elemental operations. Using a fixed set of basic operations, the visual system can assemble different routines to extract an unbounded variety of shape properties and spatial relations. At a more detailed level, a number of plausible basic operations are suggested, based primarily on their potential usefulness, and supported in part by empirical evidence. The operations discussed include shifting of the processing focus, indexing to an odd-man-out location, bounded activation, boundary tracing, and marking. The problem of assembling such elemental operations into meaningful visual routines is discussed briefly.},
  isbn = {978-0-08-051581-6},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/6ECLB77Z/B9780080515816500350.html}
}

@article{vanlieshoutWhyCuriousQuantifying2020,
  title = {Why so Curious? {{Quantifying}} Mechanisms of Information Seeking},
  shorttitle = {Why so Curious?},
  author = {{van Lieshout}, L.L.F. and {de Lange}, F.P. and Cools, R.},
  year = {2020},
  month = oct,
  journal = {Current Opinion in Behavioral Sciences},
  series = {Curiosity ({{Explore}} vs {{Exploit}})},
  volume = {35},
  pages = {112--117},
  issn = {2352-1546},
  doi = {10.1016/j.cobeha.2020.08.005},
  abstract = {Humans devote a substantial part of their time to seeking and consuming information. Often, this information is directly relevant. However, we also seek out information without obvious direct purpose. Curiosity about this type of information is called `non-instrumental curiosity'. In this review we ask why we are so curious about information that serves no direct purpose and address the psychological and neural mechanisms by which such apparently purpose-less curiosity is elicited. Non-instrumental curiosity is argued to fulfill (at least) two goals: to progressively reduce uncertainty about the world around us, and to accrue information that makes us feel good. We conclude by highlighting the promise of future psychopharmacological and neurochemical imaging studies of curiosity for elucidating the basis of both state and trait-related variation in curiosity. This is pertinent given the key implication of neurotransmitters like noradrenaline and dopamine in uncertainty reduction, reward motivation and cognitive effort.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/RCNMBTW6/S2352154620301248.html}
}

@article{vosselCorticalCouplingReflects2015,
  title = {Cortical {{Coupling Reflects Bayesian Belief Updating}} in the {{Deployment}} of {{Spatial Attention}}},
  author = {Vossel, S. and Mathys, C. and Stephan, K.E. and Friston, K.J.},
  year = {2015},
  month = aug,
  journal = {Journal of Neuroscience},
  volume = {35},
  number = {33},
  pages = {11532--11542},
  publisher = {{Society for Neuroscience}},
  issn = {0270-6474, 1529-2401},
  doi = {10.1523/JNEUROSCI.1382-15.2015},
  abstract = {The deployment of visuospatial attention and the programming of saccades are governed by the inferred likelihood of events. In the present study, we combined computational modeling of psychophysical data with fMRI to characterize the computational and neural mechanisms underlying this flexible attentional control. Sixteen healthy human subjects performed a modified version of Posner's location-cueing paradigm in which the percentage of cue validity varied in time and the targets required saccadic responses. Trialwise estimates of the certainty (precision) of the prediction that the target would appear at the cued location were derived from a hierarchical Bayesian model fitted to individual trialwise saccadic response speeds. Trial-specific model parameters then entered analyses of fMRI data as parametric regressors. Moreover, dynamic causal modeling (DCM) was performed to identify the most likely functional architecture of the attentional reorienting network and its modulation by (Bayes-optimal) precision-dependent attention. While the frontal eye fields (FEFs), intraparietal sulcus, and temporoparietal junction (TPJ) of both hemispheres showed higher activity on invalid relative to valid trials, reorienting responses in right FEF, TPJ, and the putamen were significantly modulated by precision-dependent attention. Our DCM results suggested that the precision of predictability underlies the attentional modulation of the coupling of TPJ with FEF and the putamen. Our results shed new light on the computational architecture and neuronal network dynamics underlying the context-sensitive deployment of visuospatial attention. SIGNIFICANCE STATEMENT Spatial attention and its neural correlates in the human brain have been studied extensively with the help of fMRI and cueing paradigms in which the location of targets is pre-cued on a trial-by-trial basis. One aspect that has so far been neglected concerns the question of how the brain forms attentional expectancies when no a priori probability information is available but needs to be inferred from observations. This study elucidates the computational and neural mechanisms under which probabilistic inference governs attentional deployment. Our results show that Bayesian belief updating explains changes in cortical connectivity; in that directional influences from the temporoparietal junction on the frontal eye fields and the putamen were modulated by (Bayes-optimal) updates.},
  chapter = {Articles},
  copyright = {Copyright \textcopyright{} 2015 Vossel et al..           This article is freely available online through the                 J Neurosci              Author Open Choice option.},
  langid = {english},
  pmid = {26290231},
  keywords = {attentional networks,Bayesian inference,fMRI,saccades,spatial cueing},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/68KDUID6/Vossel et al. - 2015 - Cortical Coupling Reflects Bayesian Belief Updatin.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/97YNYPIL/11532.html}
}

@article{wachterCounterfactualExplanationsOpening2017,
  title = {Counterfactual {{Explanations}} without {{Opening}} the {{Black Box}}: {{Automated Decisions}} and the {{GDPR}}},
  shorttitle = {Counterfactual {{Explanations}} without {{Opening}} the {{Black Box}}},
  author = {Wachter, S. and Mittelstadt, B. and Russell, C.},
  year = {2017},
  month = nov,
  abstract = {There has been much discussion of the right to explanation in the EU General Data Protection Regulation, and its existence, merits, and disadvantages. Implementing a right to explanation that opens the black box of algorithmic decision-making faces major legal and technical barriers. Explaining the functionality of complex algorithmic decision-making systems and their rationale in specific cases is a technically challenging problem. Some explanations may offer little meaningful information to data subjects, raising questions around their value. Explanations of automated decisions need not hinge on the general public understanding how algorithmic systems function. Even though such interpretability is of great importance and should be pursued, explanations can, in principle, be offered without opening the black box. Looking at explanations as a means to help a data subject act rather than merely understand, one could gauge the scope and content of explanations according to the specific goal or action they are intended to support. From the perspective of individuals affected by automated decision-making, we propose three aims for explanations: (1) to inform and help the individual understand why a particular decision was reached, (2) to provide grounds to contest the decision if the outcome is undesired, and (3) to understand what would need to change in order to receive a desired result in the future, based on the current decision-making model. We assess how each of these goals finds support in the GDPR. We suggest data controllers should offer a particular type of explanation, unconditional counterfactual explanations, to support these three aims. These counterfactual explanations describe the smallest change to the world that can be made to obtain a desirable outcome, or to arrive at the closest possible world, without needing to explain the internal logic of the system.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/JRAQGECE/Wachter et al. - 2017 - Counterfactual Explanations without Opening the Bl.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/2KTIRADV/1711.html}
}

@article{walkerProtectionUncertaintyExploration2020,
  title = {Protection from Uncertainty in the Exploration/Exploitation Trade-Off},
  author = {Walker, Adrian and Navarro, Danielle and Newell, Ben and Beesley, Tom},
  year = {2020},
  month = nov,
  journal = {Journal of Experimental Psychology: Learning, Memory, and Cognition},
  issn = {0278-7393},
  abstract = {The exploration/exploitation trade-off (EE trade-off) describes how, when faced with several competing alternatives, decision-makers must often choose between a known good alternative (exploitation) and one or more unknown but potentially more rewarding alternatives (exploration). Prevailing theory on how humans perform the EE trade-off states that uncertainty is a major motivator for exploration: the more uncertain the environment, the more exploration that will occur. The current paper examines whether exploratory behaviour in both choice and attention may be impacted differently depending on whether uncertainty is onset suddenly (unexpected uncertainty), or more slowly (expected uncertainty). It is shown that when uncertainty was expected, participants tended to explore less with their choices, but not their attention, than when it was unexpected. Crucially, the impact of this "protection from uncertainty" on exploration only occurred when participants had an opportunity to learn the structure of the task prior to experiencing uncertainty. This suggests that the interaction between uncertainty and exploration is more nuanced than simply more uncertainty leading to more exploration, and that attention and choice behaviour may index separate aspects of the EE trade-off.},
  copyright = {creative\_commons\_attribution\_noncommercial\_4\_0\_international\_license},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/47MSSNCU/Walker et al. - 2020 - Protection from uncertainty in the explorationexp.pdf}
}

@article{watsonDelayedDisengagementAttention2020,
  title = {Delayed Disengagement of Attention from Distractors Signalling Reward},
  author = {Watson, Poppy and Pearson, Daniel and Theeuwes, Jan and Most, Steven B. and Le Pelley, Mike E.},
  year = {2020},
  month = feb,
  journal = {Cognition},
  volume = {195},
  pages = {104125},
  issn = {0010-0277},
  doi = {10.1016/j.cognition.2019.104125},
  abstract = {Attention refers to the set of cognitive mechanisms that facilitate the prioritization of incoming sensory information. Existing research suggests that motivationally salient stimuli, such as those associated with reward, are prioritized by the attention system and that this prioritization occurs independently of an observer's goals. Specifically, studies of visual search have shown that stimuli signalling the availability of monetary reward are more likely to capture eye movements, even when participants are motivated to ignore such stimuli. In the current study we ask whether reward magnitude influences only the likelihood that stimuli will capture spatial attention, or whether reward also influences the ease with which people can disengage attention from a location when they are motivated to move their attention elsewhere. Three experiments examined the time taken to disengage from a centrally presented distractor that signalled the availability of high or low reward. We found that participants took longer to move their eyes away from a high-reward distractor, even though this came at financial cost (Experiment 1), that participants were unable to suppress a high-reward distractor consistently presented at the central location (Experiment 2), that slower responding was not due to behavioural freezing in the presence of a signal of high reward (Experiment 3), and that slower responding persisted even when rewards were no longer available (Experiment 4). These results indicate that reward modulates attentional disengagement: signals of high reward hold attention for longer, even when this is counterproductive for performance of ongoing tasks. Our findings further highlight the role of reward in the conflict between automatic and goal-directed attentional processing.},
  langid = {english},
  keywords = {Attention,Attentional capture,Cognitive control,Disengagement,Reward},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/B9ACPU5L/Watson et al. - 2020 - Delayed disengagement of attention from distractor.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/DDMII3ZM/S0010027719302999.html}
}

@article{watsonQuestBayesianAdaptive1983,
  title = {Quest: {{A Bayesian}} Adaptive Psychometric Method},
  shorttitle = {Quest},
  author = {Watson, A.B. and Pelli, D.G.},
  year = {1983},
  month = mar,
  journal = {Perception \& Psychophysics},
  volume = {33},
  number = {2},
  pages = {113--120},
  issn = {1532-5962},
  doi = {10.3758/BF03202828},
  abstract = {An adaptive psychometric procedure that places each trial at the current most probable Bayesian estimate of threshold is described. The procedure takes advantage of the common finding that the human psychometric function is invariant in form when expressed as a function of log intensity. The procedure is simple, fast, and efficient, and may be easily implemented on any computer.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/2LGHUCEC/Watson and Pelli - 1983 - Quest A Bayesian adaptive psychometric method.pdf}
}

@article{weatherholtzSociallymediatedSyntacticAlignment2014,
  title = {Socially-Mediated Syntactic Alignment},
  author = {Weatherholtz, Kodi and {Campbell-Kibler}, Kathryn and Jaeger, T. Florian},
  year = {2014},
  month = oct,
  journal = {Language Variation and Change},
  volume = {26},
  number = {3},
  pages = {387--420},
  publisher = {{Cambridge University Press}},
  issn = {0954-3945, 1469-8021},
  doi = {10.1017/S0954394514000155},
  abstract = {When we interact with one another, we tend to align our behaviors, including the way we talk. Psycholinguistic work has conceptualized alignment as the result of automatic cognitive mechanisms that operate to facilitate processing and communication. Sociolinguistic work has focused on the role of social identity and interactional strategy in explaining linguistic alignment. We draw on these two largely distinct traditions to investigate socially mediated syntactic alignment with the goal of understanding how social perception and cognition influence the mechanisms involved in alignment. A novel web-based paradigm was employed to collect speech data from a large socially heterogeneous sample. Participants listened to one of three speakers, each with a different accent, deliver an ideologically charged diatribe. Participants then completed a picture description task to assess the degree of syntactic alignment. Finally, participants completed a comprehensive social questionnaire designed to assess a wide range of social dimensions, which were tested as predictors of alignment. Our results suggest that syntactic alignment is to some extent automatic, but socially mediated. We found an overall alignment effect across social conditions and independent of social perceptions. However, the degree of alignment was influenced by a number of factors, including the perceived standardness of the passage speaker's accent, participants' perceived similarity to the speaker, and participants' preference for compromise as a conflict management style. These findings are discussed in terms of theories of linguistic alignment and speech production.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/94APJ2ZE/Weatherholtz et al. - 2014 - Socially-mediated syntactic alignment.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/F7I7DITK/08A99AE8BA59E60F5ACBB6FECB49DB48.html}
}

@article{wilcoxNewMonteCarlo1986,
  title = {New Monte Carlo Results on the Robustness of the Anova f, w and f Statistics},
  author = {Wilcox, Rand R. and Char1in, Ventura L. and Thompson, Karen L.},
  year = {1986},
  month = jan,
  journal = {Communications in Statistics - Simulation and Computation},
  volume = {15},
  number = {4},
  pages = {933--943},
  publisher = {{Taylor \& Francis}},
  issn = {0361-0918},
  doi = {10.1080/03610918608812553},
  abstract = {Because the usual F test for equal means is not robust to unequal variances, Brown and Forsythe (1974a) suggest replacing F with the statistics F or W which are based on the Satterthwaite and Welch adjusted degrees of freedom procedures. This paper reports practical situations where both F and W give * unsatisfactory results. In particular, both F and W may not provide adequate control over Type I errors. Moreover, for equal variances, but unequal sample sizes, W should be avoided in favor of F (or F ), but for equal sample sizes, and possibly unequal variances, W was the only satisfactory statistic. New results on power are included as well. The paper also considers the effect of using F or W only after a significant test for equal variances has been obtained, and new results on the robustness of the F test are described. It is found that even for equal sample sizes as large as 50 per treatment group, there are practical situations where the F test does not provide adequately control over the probability of a Type I error.},
  keywords = {heteroscedasticity,Welch and Satterthwaite adjusted degrees of freedom},
  annotation = {\_eprint: https://www.tandfonline.com/doi/pdf/10.1080/03610918608812553},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/G67MDLTV/Wilcox et al. - 1986 - New monte carlo results on the robustness of the a.pdf}
}

@book{wilkinsonMultivariateStatistics,
  title = {Multivariate {{Statistics}}},
  author = {Wilkinson, Prof Richard},
  abstract = {The lecture notes for MATH3030/4068: Multivariate Analysis / Applied Multivariate Statistics},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/8TN633PA/MATH3030.html}
}

@article{zhigalovProbingCorticalExcitability2019,
  title = {Probing Cortical Excitability Using Rapid Frequency Tagging},
  author = {Zhigalov, A. and Herring, J. D. and Herpers, J. and Bergmann, T. O. and Jensen, O.},
  year = {2019},
  month = jul,
  journal = {NeuroImage},
  volume = {195},
  pages = {59--66},
  issn = {1053-8119},
  doi = {10.1016/j.neuroimage.2019.03.056},
  abstract = {Frequency tagging has been widely used to study the role of visual selective attention. Presenting a visual stimulus flickering at a specific frequency generates so-called steady-state visually evoked responses. However, frequency tagging is mostly done at lower frequencies ({$<$}30\,Hz). This produces a visible flicker, potentially interfering with both perception and neuronal oscillations in the theta, alpha and beta band. To overcome these problems, we used a newly developed projector with a 1440\,Hz refresh rate allowing for frequency tagging at higher frequencies. We asked participants to perform a cued spatial attention task in which imperative pictorial stimuli were presented at 63\,Hz or 78\,Hz while measuring whole-head magnetoencephalography (MEG). We found posterior sensors to show a strong response at the tagged frequency. Importantly, this response was enhanced by spatial attention. Furthermore, we reproduced the typical modulations of alpha band oscillations, i.e., decrease in the alpha power contralateral to the attentional cue. The decrease in alpha power and increase in frequency tagged signal with attention correlated over subjects. We hereby provide proof-of-principle for the use of high-frequency tagging to study sensory processing and neuronal excitability associated with attention.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/LA4AF3RA/Zhigalov et al. - 2019 - Probing cortical excitability using rapid frequenc.pdf;/home/kellygarner/snap/zotero-snap/common/Zotero/storage/RR7UCHWT/S1053811919302563.html}
}

@article{zhuangContributionsGainsLosses2021,
  title = {Contributions of Gains and Losses to Attentional Capture and Disengagement: Evidence from the Gap Paradigm},
  shorttitle = {Contributions of Gains and Losses to Attentional Capture and Disengagement},
  author = {Zhuang, Ran and Tu, Yanyan and Wang, Xiangzhen and Ren, Yanju and Abrams, Richard A.},
  year = {2021},
  month = sep,
  journal = {Experimental Brain Research},
  issn = {1432-1106},
  doi = {10.1007/s00221-021-06210-9},
  abstract = {It is known that movements of visual attention are influenced by features in a scene, such as colors, that are associated with value or with loss. The present study examined the detailed nature of these attentional effects by employing the gap paradigm\textemdash a technique that has been used to separately reveal changes in attentional capture and shifting, and changes in attentional disengagement. In four experiments, participants either looked toward or away from stimuli with colors that had been associated either with gains or with losses. We found that participants were faster to look to colors associated with gains and slower to look away from them, revealing effects of gains on both attentional capture and attentional disengagement. On the other hand, participants were both slower to look to features associated with loss, and faster to look away from such features. The pattern of results suggested, however, that the latter finding was not due to more rapid disengagement from loss-associated colors, but instead to more rapid shifting of attention away from such colors. Taken together, the results reveal a complex pattern of effects of gains and losses on the disengagement, capture, and shifting of visual attention, revealing a remarkable flexibility of the attention system.},
  langid = {english},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/ZPWCKCGA/Zhuang et al. - 2021 - Contributions of gains and losses to attentional c.pdf}
}

@misc{zivonyDiachronicAccountAttentional2021,
  title = {The Diachronic Account of Attentional Selectivity},
  author = {Zivony, Alon and Eimer, Martin},
  year = {2021},
  month = mar,
  institution = {{PsyArXiv}},
  doi = {10.31234/osf.io/zja8f},
  abstract = {Many models of attention assume that attentional selection takes place at a specific moment in time which demarcates the critical transition from pre-attentive to attentive processing of sensory input. We argue that this intuitively appealing ``synchronic'' account is not only inaccurate, but has led to substantial conceptual confusion. As an alternative, we offer a ``diachronic'' framework that describes attentional selectivity as a process that unfolds over time. Key to this view is the concept of attentional episodes, brief periods of intense attentional amplification of sensory representations that regulate access to working memory and response-related processes. We describe how attentional episodes are linked to earlier attentional mechanisms and to recurrent processing at the neural level. We review studies that establish the existence of attentional episodes, delineate the factors that determine if and when they are triggered, and discuss the costs associated with processing multiple events within a single episode. Finally, we argue that this framework offers new solutions to old problems in attention research that have never been resolved. It can provide a unified and conceptually coherent account of the network of cognitive and neural processes that produce the goal-directed selectivity in perceptual processing that is commonly referred to as ``attention''.},
  keywords = {Cognitive Psychology,Neuroscience,Perception,Social and Behavioral Sciences,Theory and Philosophy of Science},
  file = {/home/kellygarner/snap/zotero-snap/common/Zotero/storage/UL29DQ6I/Zivony and Eimer - 2021 - The diachronic account of attentional selectivity.pdf}
}


